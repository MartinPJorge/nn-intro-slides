{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a simple NN for the ZDM\n",
    "\n",
    "This notebook contains the tensorflow code that illustrates the network shown in slide 10 of the presentation.\n",
    "\n",
    "So first of all, lets create fake training and test dataset. Lets assume that the defect detection camera can move across x and y axis, $x_1$ and $x_2$, respectively; between 0 and 10 cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "sum(a[:2]) / 1.5\n",
    "random.randint(0,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-axis</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x-axis  y-axis  black\n",
       "0       3      11     66\n",
       "1       6       6    238\n",
       "2       0       7    242\n",
       "3       1      11     70\n",
       "4       8       6    250"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "random.seed(datetime.now())\n",
    "\n",
    "observations = 200\n",
    "\n",
    "\n",
    "\n",
    "# Create the (x-axis, y-axis, black-intensity) dataset\n",
    "X = [\n",
    "    [\n",
    "        random.randint(0,11),  # x-axis\n",
    "        random.randint(0,11),  # y-axis\n",
    "        random.randint(0,255)  # black-intensity\n",
    "    ]\n",
    "    for _ in range(observations)\n",
    "]\n",
    "Xdf = pd.DataFrame(X, columns=['x-axis', 'y-axis', 'black'])\n",
    "\n",
    "# Now create what should be the associated actions (correct, throw-trash)\n",
    "Y = [\n",
    "    [\n",
    "        int(round(sum(x[:2]) / 22)), # correct\n",
    "        1 if x[2] > 170 else 0  # throw-trash\n",
    "    ]\n",
    "    for x in Xdf.values\n",
    "]\n",
    "Ydf = pd.DataFrame(Y, columns=['correct', 'throw-trash'])\n",
    "\n",
    "Xdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>throw-trash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct  throw-trash\n",
       "0        1            0\n",
       "1        1            1\n",
       "2        0            1\n",
       "3        1            0\n",
       "4        1            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create the NN. We're going to use keras API to build it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "NN_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Activation('relu', input_shape=[len(Xdf.keys())]), # (h1,h2,h3)\n",
    "    tf.keras.layers.Dense(2, use_bias=False), # (correct, throw-trash)=(y1,y2)\n",
    "])\n",
    "\n",
    "# Specify stocastic-gradient descend, MSE loss, and MSE as metric\n",
    "NN_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.000001),\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "\n",
    "NN_model.build()\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the model summary shows exactly that there are 6 parameters to be trained, i.e., our weights $w_1,\\ldots,w_6$ from Figure [?].\n",
    "\n",
    "Now lets do a very basic trial. We are using the 80% of the dataset to train, and the 20% to test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% train\n",
    "train_Xdf = Xdf.head(int(0.8 * len(Xdf)))\n",
    "train_Ydf = Ydf.head(int(0.8 * len(Ydf)))\n",
    "\n",
    "# 20% test\n",
    "test_Xdf = Xdf.tail(int(0.2 * len(Xdf)))\n",
    "test_Ydf = Ydf.tail(int(0.2 * len(Ydf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 32 samples\n",
      "Epoch 1/1000\n",
      "128/128 [==============================] - 0s 503us/sample - loss: 9.1899 - mse: 9.1899 - val_loss: 7.8327 - val_mse: 7.8327\n",
      "Epoch 2/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 9.1947 - mse: 9.1947 - val_loss: 7.8340 - val_mse: 7.8340\n",
      "Epoch 3/1000\n",
      "128/128 [==============================] - 0s 388us/sample - loss: 9.1792 - mse: 9.1792 - val_loss: 7.8348 - val_mse: 7.8348\n",
      "Epoch 4/1000\n",
      "128/128 [==============================] - 0s 398us/sample - loss: 9.1855 - mse: 9.1855 - val_loss: 7.8329 - val_mse: 7.8329\n",
      "Epoch 5/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 9.1836 - mse: 9.1836 - val_loss: 7.8283 - val_mse: 7.8283\n",
      "Epoch 6/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 9.1767 - mse: 9.1767 - val_loss: 7.8182 - val_mse: 7.8182\n",
      "Epoch 7/1000\n",
      "128/128 [==============================] - 0s 403us/sample - loss: 9.1722 - mse: 9.1722 - val_loss: 7.8112 - val_mse: 7.8112\n",
      "Epoch 8/1000\n",
      "128/128 [==============================] - 0s 438us/sample - loss: 9.1735 - mse: 9.1735 - val_loss: 7.8055 - val_mse: 7.8055\n",
      "Epoch 9/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 9.1647 - mse: 9.1647 - val_loss: 7.8034 - val_mse: 7.8034\n",
      "Epoch 10/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 9.1569 - mse: 9.1569 - val_loss: 7.8063 - val_mse: 7.8063\n",
      "Epoch 11/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 9.1470 - mse: 9.1470 - val_loss: 7.8027 - val_mse: 7.8027\n",
      "Epoch 12/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 9.1429 - mse: 9.1429 - val_loss: 7.7988 - val_mse: 7.7988\n",
      "Epoch 13/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 9.1423 - mse: 9.1423 - val_loss: 7.7935 - val_mse: 7.7935\n",
      "Epoch 14/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 9.1405 - mse: 9.1405 - val_loss: 7.7906 - val_mse: 7.7906\n",
      "Epoch 15/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 9.1300 - mse: 9.1300 - val_loss: 7.7882 - val_mse: 7.7882\n",
      "Epoch 16/1000\n",
      "128/128 [==============================] - 0s 413us/sample - loss: 9.1314 - mse: 9.1314 - val_loss: 7.7807 - val_mse: 7.7807\n",
      "Epoch 17/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 9.1263 - mse: 9.1263 - val_loss: 7.7733 - val_mse: 7.7733\n",
      "Epoch 18/1000\n",
      "128/128 [==============================] - 0s 444us/sample - loss: 9.1243 - mse: 9.1243 - val_loss: 7.7692 - val_mse: 7.7692\n",
      "Epoch 19/1000\n",
      "128/128 [==============================] - 0s 371us/sample - loss: 9.1253 - mse: 9.1253 - val_loss: 7.7683 - val_mse: 7.7682\n",
      "Epoch 20/1000\n",
      "128/128 [==============================] - 0s 412us/sample - loss: 9.1131 - mse: 9.1131 - val_loss: 7.7625 - val_mse: 7.7625\n",
      "Epoch 21/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 9.1096 - mse: 9.1096 - val_loss: 7.7473 - val_mse: 7.7473\n",
      "Epoch 22/1000\n",
      "128/128 [==============================] - 0s 418us/sample - loss: 9.1040 - mse: 9.1040 - val_loss: 7.7419 - val_mse: 7.7419\n",
      "Epoch 23/1000\n",
      "128/128 [==============================] - 0s 544us/sample - loss: 9.0982 - mse: 9.0982 - val_loss: 7.7465 - val_mse: 7.7465\n",
      "Epoch 24/1000\n",
      "128/128 [==============================] - 0s 539us/sample - loss: 9.0964 - mse: 9.0964 - val_loss: 7.7460 - val_mse: 7.7460\n",
      "Epoch 25/1000\n",
      "128/128 [==============================] - 0s 480us/sample - loss: 9.1004 - mse: 9.1004 - val_loss: 7.7504 - val_mse: 7.7504\n",
      "Epoch 26/1000\n",
      "128/128 [==============================] - 0s 395us/sample - loss: 9.0892 - mse: 9.0892 - val_loss: 7.7527 - val_mse: 7.7527\n",
      "Epoch 27/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 9.0856 - mse: 9.0856 - val_loss: 7.7413 - val_mse: 7.7413\n",
      "Epoch 28/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 9.0824 - mse: 9.0824 - val_loss: 7.7432 - val_mse: 7.7432\n",
      "Epoch 29/1000\n",
      "128/128 [==============================] - 0s 359us/sample - loss: 9.0818 - mse: 9.0818 - val_loss: 7.7418 - val_mse: 7.7418\n",
      "Epoch 30/1000\n",
      "128/128 [==============================] - 0s 452us/sample - loss: 9.0703 - mse: 9.0703 - val_loss: 7.7327 - val_mse: 7.7327\n",
      "Epoch 31/1000\n",
      "128/128 [==============================] - 0s 438us/sample - loss: 9.0675 - mse: 9.0675 - val_loss: 7.7322 - val_mse: 7.7322\n",
      "Epoch 32/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 9.0729 - mse: 9.0729 - val_loss: 7.7221 - val_mse: 7.7221\n",
      "Epoch 33/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 9.0547 - mse: 9.0547 - val_loss: 7.7226 - val_mse: 7.7226\n",
      "Epoch 34/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 9.0640 - mse: 9.0640 - val_loss: 7.7174 - val_mse: 7.7174\n",
      "Epoch 35/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 9.0567 - mse: 9.0567 - val_loss: 7.7083 - val_mse: 7.7083\n",
      "Epoch 36/1000\n",
      "128/128 [==============================] - 0s 412us/sample - loss: 9.0521 - mse: 9.0521 - val_loss: 7.6909 - val_mse: 7.6909\n",
      "Epoch 37/1000\n",
      "128/128 [==============================] - 0s 358us/sample - loss: 9.0436 - mse: 9.0436 - val_loss: 7.6919 - val_mse: 7.6919\n",
      "Epoch 38/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 9.0377 - mse: 9.0377 - val_loss: 7.6862 - val_mse: 7.6862\n",
      "Epoch 39/1000\n",
      "128/128 [==============================] - 0s 409us/sample - loss: 9.0314 - mse: 9.0314 - val_loss: 7.6900 - val_mse: 7.6900\n",
      "Epoch 40/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 9.0299 - mse: 9.0299 - val_loss: 7.6938 - val_mse: 7.6938\n",
      "Epoch 41/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 9.0270 - mse: 9.0270 - val_loss: 7.6876 - val_mse: 7.6876\n",
      "Epoch 42/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 9.0362 - mse: 9.0362 - val_loss: 7.6993 - val_mse: 7.6993\n",
      "Epoch 43/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 9.0157 - mse: 9.0157 - val_loss: 7.6918 - val_mse: 7.6918\n",
      "Epoch 44/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 9.0150 - mse: 9.0150 - val_loss: 7.6847 - val_mse: 7.6847\n",
      "Epoch 45/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 9.0105 - mse: 9.0105 - val_loss: 7.6788 - val_mse: 7.6788\n",
      "Epoch 46/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 9.0027 - mse: 9.0027 - val_loss: 7.6704 - val_mse: 7.6704\n",
      "Epoch 47/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 9.0019 - mse: 9.0019 - val_loss: 7.6651 - val_mse: 7.6651\n",
      "Epoch 48/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 9.0014 - mse: 9.0014 - val_loss: 7.6657 - val_mse: 7.6657\n",
      "Epoch 49/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 8.9954 - mse: 8.9954 - val_loss: 7.6648 - val_mse: 7.6648\n",
      "Epoch 50/1000\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 8.9878 - mse: 8.9878 - val_loss: 7.6569 - val_mse: 7.6569\n",
      "Epoch 51/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 8.9906 - mse: 8.9906 - val_loss: 7.6555 - val_mse: 7.6555\n",
      "Epoch 52/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 8.9749 - mse: 8.9749 - val_loss: 7.6534 - val_mse: 7.6534\n",
      "Epoch 53/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 8.9725 - mse: 8.9725 - val_loss: 7.6396 - val_mse: 7.6396\n",
      "Epoch 54/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 8.9793 - mse: 8.9793 - val_loss: 7.6382 - val_mse: 7.6382\n",
      "Epoch 55/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 8.9714 - mse: 8.9714 - val_loss: 7.6357 - val_mse: 7.6357\n",
      "Epoch 56/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 8.9739 - mse: 8.9739 - val_loss: 7.6297 - val_mse: 7.6297\n",
      "Epoch 57/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 8.9622 - mse: 8.9622 - val_loss: 7.6325 - val_mse: 7.6325\n",
      "Epoch 58/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 8.9617 - mse: 8.9617 - val_loss: 7.6235 - val_mse: 7.6235\n",
      "Epoch 59/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 8.9530 - mse: 8.9530 - val_loss: 7.6228 - val_mse: 7.6228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 8.9498 - mse: 8.9498 - val_loss: 7.6207 - val_mse: 7.6207\n",
      "Epoch 61/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 8.9451 - mse: 8.9451 - val_loss: 7.6184 - val_mse: 7.6184\n",
      "Epoch 62/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 8.9355 - mse: 8.9355 - val_loss: 7.6157 - val_mse: 7.6157\n",
      "Epoch 63/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 8.9309 - mse: 8.9309 - val_loss: 7.6115 - val_mse: 7.6115\n",
      "Epoch 64/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 8.9343 - mse: 8.9343 - val_loss: 7.6074 - val_mse: 7.6074\n",
      "Epoch 65/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 8.9280 - mse: 8.9280 - val_loss: 7.6014 - val_mse: 7.6014\n",
      "Epoch 66/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 8.9295 - mse: 8.9295 - val_loss: 7.5973 - val_mse: 7.5973\n",
      "Epoch 67/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 8.9237 - mse: 8.9237 - val_loss: 7.5856 - val_mse: 7.5856\n",
      "Epoch 68/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 8.9193 - mse: 8.9193 - val_loss: 7.5786 - val_mse: 7.5786\n",
      "Epoch 69/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 8.9243 - mse: 8.9243 - val_loss: 7.5725 - val_mse: 7.5725\n",
      "Epoch 70/1000\n",
      "128/128 [==============================] - 0s 371us/sample - loss: 8.9048 - mse: 8.9048 - val_loss: 7.5693 - val_mse: 7.5693\n",
      "Epoch 71/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 8.9020 - mse: 8.9020 - val_loss: 7.5750 - val_mse: 7.5750\n",
      "Epoch 72/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 8.9080 - mse: 8.9080 - val_loss: 7.5711 - val_mse: 7.5711\n",
      "Epoch 73/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 8.8937 - mse: 8.8937 - val_loss: 7.5673 - val_mse: 7.5673\n",
      "Epoch 74/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 8.8968 - mse: 8.8968 - val_loss: 7.5599 - val_mse: 7.5599\n",
      "Epoch 75/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 8.8886 - mse: 8.8886 - val_loss: 7.5591 - val_mse: 7.5591\n",
      "Epoch 76/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 8.8871 - mse: 8.8871 - val_loss: 7.5473 - val_mse: 7.5473\n",
      "Epoch 77/1000\n",
      "128/128 [==============================] - 0s 415us/sample - loss: 8.8871 - mse: 8.8871 - val_loss: 7.5404 - val_mse: 7.5404\n",
      "Epoch 78/1000\n",
      "128/128 [==============================] - 0s 377us/sample - loss: 8.8752 - mse: 8.8752 - val_loss: 7.5391 - val_mse: 7.5391\n",
      "Epoch 79/1000\n",
      "128/128 [==============================] - 0s 269us/sample - loss: 8.8754 - mse: 8.8754 - val_loss: 7.5321 - val_mse: 7.5321\n",
      "Epoch 80/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 8.8667 - mse: 8.8667 - val_loss: 7.5290 - val_mse: 7.5290\n",
      "Epoch 81/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 8.8697 - mse: 8.8697 - val_loss: 7.5312 - val_mse: 7.5312\n",
      "Epoch 82/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 8.8607 - mse: 8.8607 - val_loss: 7.5277 - val_mse: 7.5277\n",
      "Epoch 83/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 8.8570 - mse: 8.8570 - val_loss: 7.5315 - val_mse: 7.5315\n",
      "Epoch 84/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 8.8492 - mse: 8.8492 - val_loss: 7.5278 - val_mse: 7.5278\n",
      "Epoch 85/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 8.8503 - mse: 8.8503 - val_loss: 7.5236 - val_mse: 7.5236\n",
      "Epoch 86/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 8.8472 - mse: 8.8472 - val_loss: 7.5185 - val_mse: 7.5185\n",
      "Epoch 87/1000\n",
      "128/128 [==============================] - 0s 263us/sample - loss: 8.8353 - mse: 8.8353 - val_loss: 7.5143 - val_mse: 7.5143\n",
      "Epoch 88/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 8.8437 - mse: 8.8437 - val_loss: 7.5199 - val_mse: 7.5199\n",
      "Epoch 89/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 8.8308 - mse: 8.8308 - val_loss: 7.5151 - val_mse: 7.5151\n",
      "Epoch 90/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 8.8321 - mse: 8.8321 - val_loss: 7.4983 - val_mse: 7.4983\n",
      "Epoch 91/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 8.8249 - mse: 8.8249 - val_loss: 7.4960 - val_mse: 7.4960\n",
      "Epoch 92/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 8.8255 - mse: 8.8255 - val_loss: 7.4917 - val_mse: 7.4917\n",
      "Epoch 93/1000\n",
      "128/128 [==============================] - 0s 269us/sample - loss: 8.8151 - mse: 8.8151 - val_loss: 7.4902 - val_mse: 7.4902\n",
      "Epoch 94/1000\n",
      "128/128 [==============================] - 0s 233us/sample - loss: 8.8104 - mse: 8.8104 - val_loss: 7.4901 - val_mse: 7.4901\n",
      "Epoch 95/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 8.8109 - mse: 8.8109 - val_loss: 7.4881 - val_mse: 7.4881\n",
      "Epoch 96/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 8.7989 - mse: 8.7989 - val_loss: 7.4857 - val_mse: 7.4857\n",
      "Epoch 97/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 8.7998 - mse: 8.7998 - val_loss: 7.4784 - val_mse: 7.4784\n",
      "Epoch 98/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 8.8036 - mse: 8.8036 - val_loss: 7.4746 - val_mse: 7.4746\n",
      "Epoch 99/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 8.8097 - mse: 8.8097 - val_loss: 7.4814 - val_mse: 7.4814\n",
      "Epoch 100/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 8.7894 - mse: 8.7894 - val_loss: 7.4655 - val_mse: 7.4655\n",
      "Epoch 101/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 8.7838 - mse: 8.7838 - val_loss: 7.4636 - val_mse: 7.4636\n",
      "Epoch 102/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 8.7784 - mse: 8.7784 - val_loss: 7.4748 - val_mse: 7.4748\n",
      "Epoch 103/1000\n",
      "128/128 [==============================] - 0s 270us/sample - loss: 8.7775 - mse: 8.7775 - val_loss: 7.4682 - val_mse: 7.4682\n",
      "Epoch 104/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 8.7802 - mse: 8.7802 - val_loss: 7.4696 - val_mse: 7.4696\n",
      "Epoch 105/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 8.7762 - mse: 8.7762 - val_loss: 7.4678 - val_mse: 7.4678\n",
      "Epoch 106/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 8.7665 - mse: 8.7665 - val_loss: 7.4655 - val_mse: 7.4655\n",
      "Epoch 107/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 8.7612 - mse: 8.7612 - val_loss: 7.4544 - val_mse: 7.4544\n",
      "Epoch 108/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 8.7568 - mse: 8.7568 - val_loss: 7.4502 - val_mse: 7.4502\n",
      "Epoch 109/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 8.7479 - mse: 8.7479 - val_loss: 7.4374 - val_mse: 7.4374\n",
      "Epoch 110/1000\n",
      "128/128 [==============================] - 0s 440us/sample - loss: 8.7548 - mse: 8.7548 - val_loss: 7.4317 - val_mse: 7.4317\n",
      "Epoch 111/1000\n",
      "128/128 [==============================] - 0s 380us/sample - loss: 8.7514 - mse: 8.7514 - val_loss: 7.4222 - val_mse: 7.4222\n",
      "Epoch 112/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 8.7421 - mse: 8.7421 - val_loss: 7.4172 - val_mse: 7.4172\n",
      "Epoch 113/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 8.7330 - mse: 8.7330 - val_loss: 7.4128 - val_mse: 7.4128\n",
      "Epoch 114/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 8.7426 - mse: 8.7426 - val_loss: 7.4063 - val_mse: 7.4063\n",
      "Epoch 115/1000\n",
      "128/128 [==============================] - 0s 486us/sample - loss: 8.7316 - mse: 8.7316 - val_loss: 7.4096 - val_mse: 7.4096\n",
      "Epoch 116/1000\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 8.7229 - mse: 8.7229 - val_loss: 7.4081 - val_mse: 7.4081\n",
      "Epoch 117/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 8.7190 - mse: 8.7190 - val_loss: 7.4080 - val_mse: 7.4080\n",
      "Epoch 118/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 8.7086 - mse: 8.7086 - val_loss: 7.4128 - val_mse: 7.4128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 8.7126 - mse: 8.7126 - val_loss: 7.4201 - val_mse: 7.4201\n",
      "Epoch 120/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 8.7114 - mse: 8.7114 - val_loss: 7.4074 - val_mse: 7.4074\n",
      "Epoch 121/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 8.7036 - mse: 8.7036 - val_loss: 7.4001 - val_mse: 7.4001\n",
      "Epoch 122/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 8.7103 - mse: 8.7103 - val_loss: 7.3890 - val_mse: 7.3890\n",
      "Epoch 123/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 8.6981 - mse: 8.6981 - val_loss: 7.3792 - val_mse: 7.3792\n",
      "Epoch 124/1000\n",
      "128/128 [==============================] - 0s 270us/sample - loss: 8.6976 - mse: 8.6976 - val_loss: 7.3730 - val_mse: 7.3730\n",
      "Epoch 125/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 8.6902 - mse: 8.6902 - val_loss: 7.3618 - val_mse: 7.3618\n",
      "Epoch 126/1000\n",
      "128/128 [==============================] - 0s 433us/sample - loss: 8.6828 - mse: 8.6828 - val_loss: 7.3648 - val_mse: 7.3648\n",
      "Epoch 127/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 8.6781 - mse: 8.6781 - val_loss: 7.3765 - val_mse: 7.3765\n",
      "Epoch 128/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 8.6771 - mse: 8.6771 - val_loss: 7.3743 - val_mse: 7.3743\n",
      "Epoch 129/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 8.6738 - mse: 8.6738 - val_loss: 7.3755 - val_mse: 7.3755\n",
      "Epoch 130/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 8.6754 - mse: 8.6754 - val_loss: 7.3607 - val_mse: 7.3607\n",
      "Epoch 131/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 8.6703 - mse: 8.6703 - val_loss: 7.3557 - val_mse: 7.3557\n",
      "Epoch 132/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 8.6595 - mse: 8.6595 - val_loss: 7.3562 - val_mse: 7.3562\n",
      "Epoch 133/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 8.6540 - mse: 8.6540 - val_loss: 7.3479 - val_mse: 7.3479\n",
      "Epoch 134/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 8.6609 - mse: 8.6609 - val_loss: 7.3656 - val_mse: 7.3656\n",
      "Epoch 135/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 8.6549 - mse: 8.6549 - val_loss: 7.3519 - val_mse: 7.3519\n",
      "Epoch 136/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 8.6421 - mse: 8.6421 - val_loss: 7.3480 - val_mse: 7.3480\n",
      "Epoch 137/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 8.6409 - mse: 8.6409 - val_loss: 7.3427 - val_mse: 7.3427\n",
      "Epoch 138/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 8.6452 - mse: 8.6452 - val_loss: 7.3344 - val_mse: 7.3344\n",
      "Epoch 139/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 8.6351 - mse: 8.6351 - val_loss: 7.3371 - val_mse: 7.3371\n",
      "Epoch 140/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 8.6301 - mse: 8.6301 - val_loss: 7.3290 - val_mse: 7.3290\n",
      "Epoch 141/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 8.6275 - mse: 8.6275 - val_loss: 7.3231 - val_mse: 7.3231\n",
      "Epoch 142/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 8.6172 - mse: 8.6172 - val_loss: 7.3186 - val_mse: 7.3186\n",
      "Epoch 143/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 8.6202 - mse: 8.6202 - val_loss: 7.3136 - val_mse: 7.3136\n",
      "Epoch 144/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 8.6113 - mse: 8.6113 - val_loss: 7.3035 - val_mse: 7.3035\n",
      "Epoch 145/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 8.6086 - mse: 8.6086 - val_loss: 7.3027 - val_mse: 7.3027\n",
      "Epoch 146/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 8.6103 - mse: 8.6103 - val_loss: 7.3012 - val_mse: 7.3012\n",
      "Epoch 147/1000\n",
      "128/128 [==============================] - 0s 393us/sample - loss: 8.5996 - mse: 8.5996 - val_loss: 7.2978 - val_mse: 7.2978\n",
      "Epoch 148/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 8.6023 - mse: 8.6023 - val_loss: 7.2907 - val_mse: 7.2907\n",
      "Epoch 149/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 8.5991 - mse: 8.5991 - val_loss: 7.2903 - val_mse: 7.2903\n",
      "Epoch 150/1000\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 8.5908 - mse: 8.5908 - val_loss: 7.2809 - val_mse: 7.2809\n",
      "Epoch 151/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 8.5856 - mse: 8.5856 - val_loss: 7.2842 - val_mse: 7.2842\n",
      "Epoch 152/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 8.5841 - mse: 8.5841 - val_loss: 7.2819 - val_mse: 7.2819\n",
      "Epoch 153/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 8.5777 - mse: 8.5777 - val_loss: 7.2840 - val_mse: 7.2840\n",
      "Epoch 154/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 8.5797 - mse: 8.5797 - val_loss: 7.2861 - val_mse: 7.2861\n",
      "Epoch 155/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 8.5752 - mse: 8.5752 - val_loss: 7.2833 - val_mse: 7.2833\n",
      "Epoch 156/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 8.5713 - mse: 8.5713 - val_loss: 7.2757 - val_mse: 7.2757\n",
      "Epoch 157/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 8.5638 - mse: 8.5638 - val_loss: 7.2622 - val_mse: 7.2622\n",
      "Epoch 158/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 8.5688 - mse: 8.5688 - val_loss: 7.2687 - val_mse: 7.2687\n",
      "Epoch 159/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 8.5541 - mse: 8.5541 - val_loss: 7.2640 - val_mse: 7.2640\n",
      "Epoch 160/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 8.5603 - mse: 8.5603 - val_loss: 7.2683 - val_mse: 7.2683\n",
      "Epoch 161/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 8.5495 - mse: 8.5495 - val_loss: 7.2638 - val_mse: 7.2638\n",
      "Epoch 162/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 8.5420 - mse: 8.5420 - val_loss: 7.2466 - val_mse: 7.2466\n",
      "Epoch 163/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 8.5390 - mse: 8.5390 - val_loss: 7.2470 - val_mse: 7.2470\n",
      "Epoch 164/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 8.5438 - mse: 8.5438 - val_loss: 7.2410 - val_mse: 7.2410\n",
      "Epoch 165/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 8.5323 - mse: 8.5323 - val_loss: 7.2401 - val_mse: 7.2401\n",
      "Epoch 166/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 8.5341 - mse: 8.5341 - val_loss: 7.2386 - val_mse: 7.2386\n",
      "Epoch 167/1000\n",
      "128/128 [==============================] - 0s 364us/sample - loss: 8.5276 - mse: 8.5276 - val_loss: 7.2166 - val_mse: 7.2166\n",
      "Epoch 168/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 8.5202 - mse: 8.5202 - val_loss: 7.2141 - val_mse: 7.2141\n",
      "Epoch 169/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 8.5174 - mse: 8.5174 - val_loss: 7.2030 - val_mse: 7.2030\n",
      "Epoch 170/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 8.5239 - mse: 8.5239 - val_loss: 7.2039 - val_mse: 7.2039\n",
      "Epoch 171/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 8.5103 - mse: 8.5103 - val_loss: 7.2107 - val_mse: 7.2107\n",
      "Epoch 172/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 8.5109 - mse: 8.5109 - val_loss: 7.2070 - val_mse: 7.2070\n",
      "Epoch 173/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 8.5060 - mse: 8.5060 - val_loss: 7.2004 - val_mse: 7.2004\n",
      "Epoch 174/1000\n",
      "128/128 [==============================] - 0s 380us/sample - loss: 8.5008 - mse: 8.5008 - val_loss: 7.1916 - val_mse: 7.1916\n",
      "Epoch 175/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 8.4942 - mse: 8.4942 - val_loss: 7.1896 - val_mse: 7.1896\n",
      "Epoch 176/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 8.4906 - mse: 8.4906 - val_loss: 7.1922 - val_mse: 7.1922\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 275us/sample - loss: 8.4940 - mse: 8.4940 - val_loss: 7.1922 - val_mse: 7.1922\n",
      "Epoch 178/1000\n",
      "128/128 [==============================] - 0s 255us/sample - loss: 8.4859 - mse: 8.4859 - val_loss: 7.1829 - val_mse: 7.1829\n",
      "Epoch 179/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 8.4840 - mse: 8.4840 - val_loss: 7.1866 - val_mse: 7.1866\n",
      "Epoch 180/1000\n",
      "128/128 [==============================] - 0s 261us/sample - loss: 8.4777 - mse: 8.4777 - val_loss: 7.1835 - val_mse: 7.1835\n",
      "Epoch 181/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 8.4696 - mse: 8.4696 - val_loss: 7.1742 - val_mse: 7.1742\n",
      "Epoch 182/1000\n",
      "128/128 [==============================] - 0s 237us/sample - loss: 8.4648 - mse: 8.4648 - val_loss: 7.1734 - val_mse: 7.1734\n",
      "Epoch 183/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 8.4620 - mse: 8.4620 - val_loss: 7.1724 - val_mse: 7.1724\n",
      "Epoch 184/1000\n",
      "128/128 [==============================] - 0s 247us/sample - loss: 8.4619 - mse: 8.4619 - val_loss: 7.1690 - val_mse: 7.1690\n",
      "Epoch 185/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 8.4685 - mse: 8.4685 - val_loss: 7.1612 - val_mse: 7.1612\n",
      "Epoch 186/1000\n",
      "128/128 [==============================] - 0s 359us/sample - loss: 8.4588 - mse: 8.4588 - val_loss: 7.1509 - val_mse: 7.1509\n",
      "Epoch 187/1000\n",
      "128/128 [==============================] - 0s 412us/sample - loss: 8.4528 - mse: 8.4528 - val_loss: 7.1528 - val_mse: 7.1528\n",
      "Epoch 188/1000\n",
      "128/128 [==============================] - 0s 434us/sample - loss: 8.4488 - mse: 8.4488 - val_loss: 7.1502 - val_mse: 7.1502\n",
      "Epoch 189/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 8.4377 - mse: 8.4377 - val_loss: 7.1498 - val_mse: 7.1498\n",
      "Epoch 190/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 8.4435 - mse: 8.4435 - val_loss: 7.1475 - val_mse: 7.1475\n",
      "Epoch 191/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 8.4274 - mse: 8.4274 - val_loss: 7.1449 - val_mse: 7.1449\n",
      "Epoch 192/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 8.4309 - mse: 8.4309 - val_loss: 7.1426 - val_mse: 7.1426\n",
      "Epoch 193/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 8.4251 - mse: 8.4251 - val_loss: 7.1387 - val_mse: 7.1387\n",
      "Epoch 194/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 8.4268 - mse: 8.4268 - val_loss: 7.1423 - val_mse: 7.1423\n",
      "Epoch 195/1000\n",
      "128/128 [==============================] - 0s 259us/sample - loss: 8.4220 - mse: 8.4220 - val_loss: 7.1371 - val_mse: 7.1371\n",
      "Epoch 196/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 8.4212 - mse: 8.4212 - val_loss: 7.1345 - val_mse: 7.1345\n",
      "Epoch 197/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 8.4106 - mse: 8.4106 - val_loss: 7.1351 - val_mse: 7.1351\n",
      "Epoch 198/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 8.4057 - mse: 8.4057 - val_loss: 7.1366 - val_mse: 7.1366\n",
      "Epoch 199/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 8.4012 - mse: 8.4012 - val_loss: 7.1274 - val_mse: 7.1274\n",
      "Epoch 200/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 8.4080 - mse: 8.4080 - val_loss: 7.1228 - val_mse: 7.1228\n",
      "Epoch 201/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 8.3989 - mse: 8.3989 - val_loss: 7.1067 - val_mse: 7.1067\n",
      "Epoch 202/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 8.3990 - mse: 8.3990 - val_loss: 7.1056 - val_mse: 7.1056\n",
      "Epoch 203/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 8.3892 - mse: 8.3892 - val_loss: 7.1063 - val_mse: 7.1063\n",
      "Epoch 204/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 8.3799 - mse: 8.3799 - val_loss: 7.0984 - val_mse: 7.0984\n",
      "Epoch 205/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 8.3761 - mse: 8.3761 - val_loss: 7.0994 - val_mse: 7.0994\n",
      "Epoch 206/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 8.3781 - mse: 8.3781 - val_loss: 7.0887 - val_mse: 7.0887\n",
      "Epoch 207/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 8.3716 - mse: 8.3716 - val_loss: 7.0922 - val_mse: 7.0922\n",
      "Epoch 208/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 8.3720 - mse: 8.3720 - val_loss: 7.0863 - val_mse: 7.0863\n",
      "Epoch 209/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 8.3630 - mse: 8.3630 - val_loss: 7.0812 - val_mse: 7.0812\n",
      "Epoch 210/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 8.3641 - mse: 8.3641 - val_loss: 7.0828 - val_mse: 7.0828\n",
      "Epoch 211/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 8.3606 - mse: 8.3606 - val_loss: 7.0743 - val_mse: 7.0743\n",
      "Epoch 212/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 8.3564 - mse: 8.3564 - val_loss: 7.0633 - val_mse: 7.0633\n",
      "Epoch 213/1000\n",
      "128/128 [==============================] - 0s 411us/sample - loss: 8.3518 - mse: 8.3518 - val_loss: 7.0688 - val_mse: 7.0688\n",
      "Epoch 214/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 8.3538 - mse: 8.3538 - val_loss: 7.0630 - val_mse: 7.0630\n",
      "Epoch 215/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 8.3543 - mse: 8.3543 - val_loss: 7.0607 - val_mse: 7.0607\n",
      "Epoch 216/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 8.3445 - mse: 8.3445 - val_loss: 7.0556 - val_mse: 7.0556\n",
      "Epoch 217/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 8.3478 - mse: 8.3478 - val_loss: 7.0521 - val_mse: 7.0521\n",
      "Epoch 218/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 8.3298 - mse: 8.3298 - val_loss: 7.0580 - val_mse: 7.0580\n",
      "Epoch 219/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 8.3282 - mse: 8.3282 - val_loss: 7.0581 - val_mse: 7.0581\n",
      "Epoch 220/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 8.3226 - mse: 8.3226 - val_loss: 7.0523 - val_mse: 7.0523\n",
      "Epoch 221/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 8.3267 - mse: 8.3267 - val_loss: 7.0452 - val_mse: 7.0452\n",
      "Epoch 222/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 8.3118 - mse: 8.3118 - val_loss: 7.0329 - val_mse: 7.0329\n",
      "Epoch 223/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 8.3181 - mse: 8.3181 - val_loss: 7.0308 - val_mse: 7.0308\n",
      "Epoch 224/1000\n",
      "128/128 [==============================] - 0s 404us/sample - loss: 8.3076 - mse: 8.3076 - val_loss: 7.0343 - val_mse: 7.0343\n",
      "Epoch 225/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 8.3054 - mse: 8.3054 - val_loss: 7.0286 - val_mse: 7.0286\n",
      "Epoch 226/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 8.3061 - mse: 8.3061 - val_loss: 7.0175 - val_mse: 7.0175\n",
      "Epoch 227/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 8.2967 - mse: 8.2967 - val_loss: 7.0074 - val_mse: 7.0074\n",
      "Epoch 228/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 8.2951 - mse: 8.2951 - val_loss: 7.0118 - val_mse: 7.0118\n",
      "Epoch 229/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 8.2893 - mse: 8.2893 - val_loss: 7.0081 - val_mse: 7.0081\n",
      "Epoch 230/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 8.2830 - mse: 8.2830 - val_loss: 7.0064 - val_mse: 7.0064\n",
      "Epoch 231/1000\n",
      "128/128 [==============================] - 0s 358us/sample - loss: 8.2856 - mse: 8.2856 - val_loss: 7.0124 - val_mse: 7.0124\n",
      "Epoch 232/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 8.2775 - mse: 8.2775 - val_loss: 7.0029 - val_mse: 7.0029\n",
      "Epoch 233/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 8.2801 - mse: 8.2801 - val_loss: 6.9930 - val_mse: 6.9930\n",
      "Epoch 234/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 8.2781 - mse: 8.2781 - val_loss: 6.9826 - val_mse: 6.9826\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 323us/sample - loss: 8.2684 - mse: 8.2684 - val_loss: 6.9786 - val_mse: 6.9786\n",
      "Epoch 236/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 8.2566 - mse: 8.2566 - val_loss: 6.9811 - val_mse: 6.9811\n",
      "Epoch 237/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 8.2582 - mse: 8.2582 - val_loss: 6.9900 - val_mse: 6.9900\n",
      "Epoch 238/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 8.2581 - mse: 8.2580 - val_loss: 6.9801 - val_mse: 6.9801\n",
      "Epoch 239/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 8.2498 - mse: 8.2498 - val_loss: 6.9765 - val_mse: 6.9765\n",
      "Epoch 240/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 8.2625 - mse: 8.2625 - val_loss: 6.9719 - val_mse: 6.9719\n",
      "Epoch 241/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 8.2432 - mse: 8.2432 - val_loss: 6.9646 - val_mse: 6.9646\n",
      "Epoch 242/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 8.2529 - mse: 8.2529 - val_loss: 6.9569 - val_mse: 6.9569\n",
      "Epoch 243/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 8.2479 - mse: 8.2479 - val_loss: 6.9450 - val_mse: 6.9450\n",
      "Epoch 244/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 8.2301 - mse: 8.2301 - val_loss: 6.9492 - val_mse: 6.9492\n",
      "Epoch 245/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 8.2354 - mse: 8.2354 - val_loss: 6.9545 - val_mse: 6.9545\n",
      "Epoch 246/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 8.2260 - mse: 8.2260 - val_loss: 6.9552 - val_mse: 6.9552\n",
      "Epoch 247/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 8.2245 - mse: 8.2245 - val_loss: 6.9532 - val_mse: 6.9532\n",
      "Epoch 248/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 8.2291 - mse: 8.2291 - val_loss: 6.9501 - val_mse: 6.9501\n",
      "Epoch 249/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 8.2092 - mse: 8.2092 - val_loss: 6.9447 - val_mse: 6.9447\n",
      "Epoch 250/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 8.2198 - mse: 8.2198 - val_loss: 6.9460 - val_mse: 6.9460\n",
      "Epoch 251/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 8.2083 - mse: 8.2083 - val_loss: 6.9411 - val_mse: 6.9411\n",
      "Epoch 252/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 8.2022 - mse: 8.2022 - val_loss: 6.9330 - val_mse: 6.9330\n",
      "Epoch 253/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 8.2009 - mse: 8.2009 - val_loss: 6.9289 - val_mse: 6.9289\n",
      "Epoch 254/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 8.2020 - mse: 8.2020 - val_loss: 6.9239 - val_mse: 6.9239\n",
      "Epoch 255/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 8.1922 - mse: 8.1922 - val_loss: 6.9185 - val_mse: 6.9185\n",
      "Epoch 256/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 8.1894 - mse: 8.1894 - val_loss: 6.9202 - val_mse: 6.9202\n",
      "Epoch 257/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 8.1857 - mse: 8.1857 - val_loss: 6.9182 - val_mse: 6.9182\n",
      "Epoch 258/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 8.1848 - mse: 8.1848 - val_loss: 6.9164 - val_mse: 6.9164\n",
      "Epoch 259/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 8.1745 - mse: 8.1745 - val_loss: 6.9148 - val_mse: 6.9148\n",
      "Epoch 260/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 8.1750 - mse: 8.1750 - val_loss: 6.9132 - val_mse: 6.9132\n",
      "Epoch 261/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 8.1699 - mse: 8.1699 - val_loss: 6.9088 - val_mse: 6.9088\n",
      "Epoch 262/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 8.1643 - mse: 8.1643 - val_loss: 6.9004 - val_mse: 6.9004\n",
      "Epoch 263/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 8.1680 - mse: 8.1680 - val_loss: 6.8967 - val_mse: 6.8967\n",
      "Epoch 264/1000\n",
      "128/128 [==============================] - 0s 252us/sample - loss: 8.1662 - mse: 8.1662 - val_loss: 6.8929 - val_mse: 6.8929\n",
      "Epoch 265/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 8.1571 - mse: 8.1571 - val_loss: 6.8883 - val_mse: 6.8883\n",
      "Epoch 266/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 8.1504 - mse: 8.1504 - val_loss: 6.8852 - val_mse: 6.8852\n",
      "Epoch 267/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 8.1503 - mse: 8.1503 - val_loss: 6.8805 - val_mse: 6.8805\n",
      "Epoch 268/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 8.1436 - mse: 8.1436 - val_loss: 6.8792 - val_mse: 6.8792\n",
      "Epoch 269/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 8.1480 - mse: 8.1480 - val_loss: 6.8799 - val_mse: 6.8799\n",
      "Epoch 270/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 8.1380 - mse: 8.1380 - val_loss: 6.8901 - val_mse: 6.8901\n",
      "Epoch 271/1000\n",
      "128/128 [==============================] - 0s 392us/sample - loss: 8.1404 - mse: 8.1404 - val_loss: 6.8776 - val_mse: 6.8776\n",
      "Epoch 272/1000\n",
      "128/128 [==============================] - 0s 410us/sample - loss: 8.1336 - mse: 8.1336 - val_loss: 6.8639 - val_mse: 6.8639\n",
      "Epoch 273/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 8.1277 - mse: 8.1277 - val_loss: 6.8699 - val_mse: 6.8699\n",
      "Epoch 274/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 8.1265 - mse: 8.1265 - val_loss: 6.8625 - val_mse: 6.8625\n",
      "Epoch 275/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 8.1246 - mse: 8.1246 - val_loss: 6.8586 - val_mse: 6.8586\n",
      "Epoch 276/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 8.1272 - mse: 8.1272 - val_loss: 6.8507 - val_mse: 6.8507\n",
      "Epoch 277/1000\n",
      "128/128 [==============================] - 0s 270us/sample - loss: 8.1181 - mse: 8.1181 - val_loss: 6.8421 - val_mse: 6.8421\n",
      "Epoch 278/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 8.1106 - mse: 8.1106 - val_loss: 6.8369 - val_mse: 6.8369\n",
      "Epoch 279/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 8.1079 - mse: 8.1079 - val_loss: 6.8282 - val_mse: 6.8282\n",
      "Epoch 280/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 8.1020 - mse: 8.1020 - val_loss: 6.8270 - val_mse: 6.8270\n",
      "Epoch 281/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 8.0971 - mse: 8.0971 - val_loss: 6.8203 - val_mse: 6.8203\n",
      "Epoch 282/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 8.1042 - mse: 8.1042 - val_loss: 6.8193 - val_mse: 6.8193\n",
      "Epoch 283/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 8.0940 - mse: 8.0940 - val_loss: 6.8132 - val_mse: 6.8132\n",
      "Epoch 284/1000\n",
      "128/128 [==============================] - 0s 261us/sample - loss: 8.0894 - mse: 8.0894 - val_loss: 6.8075 - val_mse: 6.8075\n",
      "Epoch 285/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 8.0819 - mse: 8.0819 - val_loss: 6.8086 - val_mse: 6.8086\n",
      "Epoch 286/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 8.0838 - mse: 8.0838 - val_loss: 6.7976 - val_mse: 6.7976\n",
      "Epoch 287/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 8.0796 - mse: 8.0796 - val_loss: 6.8056 - val_mse: 6.8056\n",
      "Epoch 288/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 8.0736 - mse: 8.0736 - val_loss: 6.8039 - val_mse: 6.8039\n",
      "Epoch 289/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 8.0705 - mse: 8.0705 - val_loss: 6.8030 - val_mse: 6.8030\n",
      "Epoch 290/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 8.0636 - mse: 8.0636 - val_loss: 6.8092 - val_mse: 6.8092\n",
      "Epoch 291/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 8.0644 - mse: 8.0644 - val_loss: 6.8098 - val_mse: 6.8098\n",
      "Epoch 292/1000\n",
      "128/128 [==============================] - 0s 359us/sample - loss: 8.0618 - mse: 8.0618 - val_loss: 6.7996 - val_mse: 6.7996\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 399us/sample - loss: 8.0516 - mse: 8.0516 - val_loss: 6.7940 - val_mse: 6.7940\n",
      "Epoch 294/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 8.0494 - mse: 8.0494 - val_loss: 6.8024 - val_mse: 6.8024\n",
      "Epoch 295/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 8.0545 - mse: 8.0545 - val_loss: 6.7972 - val_mse: 6.7972\n",
      "Epoch 296/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 8.0418 - mse: 8.0418 - val_loss: 6.7869 - val_mse: 6.7869\n",
      "Epoch 297/1000\n",
      "128/128 [==============================] - 0s 383us/sample - loss: 8.0458 - mse: 8.0458 - val_loss: 6.7948 - val_mse: 6.7948\n",
      "Epoch 298/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 8.0389 - mse: 8.0389 - val_loss: 6.7961 - val_mse: 6.7961\n",
      "Epoch 299/1000\n",
      "128/128 [==============================] - 0s 401us/sample - loss: 8.0370 - mse: 8.0370 - val_loss: 6.7769 - val_mse: 6.7769\n",
      "Epoch 300/1000\n",
      "128/128 [==============================] - 0s 406us/sample - loss: 8.0325 - mse: 8.0325 - val_loss: 6.7796 - val_mse: 6.7796\n",
      "Epoch 301/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 8.0264 - mse: 8.0264 - val_loss: 6.7756 - val_mse: 6.7756\n",
      "Epoch 302/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 8.0182 - mse: 8.0182 - val_loss: 6.7681 - val_mse: 6.7681\n",
      "Epoch 303/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 8.0217 - mse: 8.0217 - val_loss: 6.7540 - val_mse: 6.7540\n",
      "Epoch 304/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 8.0136 - mse: 8.0136 - val_loss: 6.7532 - val_mse: 6.7532\n",
      "Epoch 305/1000\n",
      "128/128 [==============================] - 0s 439us/sample - loss: 8.0094 - mse: 8.0094 - val_loss: 6.7478 - val_mse: 6.7478\n",
      "Epoch 306/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 8.0159 - mse: 8.0159 - val_loss: 6.7516 - val_mse: 6.7516\n",
      "Epoch 307/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 8.0028 - mse: 8.0028 - val_loss: 6.7513 - val_mse: 6.7513\n",
      "Epoch 308/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 8.0018 - mse: 8.0018 - val_loss: 6.7446 - val_mse: 6.7446\n",
      "Epoch 309/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 7.9992 - mse: 7.9992 - val_loss: 6.7394 - val_mse: 6.7394\n",
      "Epoch 310/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 7.9970 - mse: 7.9970 - val_loss: 6.7394 - val_mse: 6.7394\n",
      "Epoch 311/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 7.9947 - mse: 7.9947 - val_loss: 6.7372 - val_mse: 6.7372\n",
      "Epoch 312/1000\n",
      "128/128 [==============================] - 0s 269us/sample - loss: 7.9871 - mse: 7.9871 - val_loss: 6.7349 - val_mse: 6.7349\n",
      "Epoch 313/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 7.9784 - mse: 7.9784 - val_loss: 6.7276 - val_mse: 6.7276\n",
      "Epoch 314/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 7.9805 - mse: 7.9805 - val_loss: 6.7208 - val_mse: 6.7208\n",
      "Epoch 315/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 7.9745 - mse: 7.9745 - val_loss: 6.7205 - val_mse: 6.7205\n",
      "Epoch 316/1000\n",
      "128/128 [==============================] - 0s 246us/sample - loss: 7.9723 - mse: 7.9723 - val_loss: 6.7209 - val_mse: 6.7209\n",
      "Epoch 317/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 7.9720 - mse: 7.9720 - val_loss: 6.7168 - val_mse: 6.7168\n",
      "Epoch 318/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 7.9675 - mse: 7.9675 - val_loss: 6.7151 - val_mse: 6.7151\n",
      "Epoch 319/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 7.9594 - mse: 7.9594 - val_loss: 6.7102 - val_mse: 6.7102\n",
      "Epoch 320/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 7.9544 - mse: 7.9544 - val_loss: 6.7101 - val_mse: 6.7101\n",
      "Epoch 321/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 7.9550 - mse: 7.9550 - val_loss: 6.7070 - val_mse: 6.7070\n",
      "Epoch 322/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 7.9618 - mse: 7.9618 - val_loss: 6.7059 - val_mse: 6.7059\n",
      "Epoch 323/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 7.9474 - mse: 7.9474 - val_loss: 6.7019 - val_mse: 6.7019\n",
      "Epoch 324/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 7.9527 - mse: 7.9527 - val_loss: 6.6963 - val_mse: 6.6963\n",
      "Epoch 325/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.9504 - mse: 7.9504 - val_loss: 6.6948 - val_mse: 6.6948\n",
      "Epoch 326/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 7.9424 - mse: 7.9424 - val_loss: 6.6873 - val_mse: 6.6873\n",
      "Epoch 327/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 7.9341 - mse: 7.9341 - val_loss: 6.6901 - val_mse: 6.6901\n",
      "Epoch 328/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 7.9451 - mse: 7.9451 - val_loss: 6.6965 - val_mse: 6.6965\n",
      "Epoch 329/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.9294 - mse: 7.9294 - val_loss: 6.6763 - val_mse: 6.6763\n",
      "Epoch 330/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 7.9199 - mse: 7.9199 - val_loss: 6.6793 - val_mse: 6.6793\n",
      "Epoch 331/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 7.9197 - mse: 7.9197 - val_loss: 6.6722 - val_mse: 6.6722\n",
      "Epoch 332/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 7.9132 - mse: 7.9132 - val_loss: 6.6661 - val_mse: 6.6661\n",
      "Epoch 333/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 7.9138 - mse: 7.9138 - val_loss: 6.6585 - val_mse: 6.6585\n",
      "Epoch 334/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 7.9107 - mse: 7.9107 - val_loss: 6.6625 - val_mse: 6.6625\n",
      "Epoch 335/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 7.9134 - mse: 7.9134 - val_loss: 6.6552 - val_mse: 6.6552\n",
      "Epoch 336/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.8956 - mse: 7.8956 - val_loss: 6.6537 - val_mse: 6.6537\n",
      "Epoch 337/1000\n",
      "128/128 [==============================] - 0s 391us/sample - loss: 7.9034 - mse: 7.9034 - val_loss: 6.6644 - val_mse: 6.6644\n",
      "Epoch 338/1000\n",
      "128/128 [==============================] - 0s 352us/sample - loss: 7.8943 - mse: 7.8943 - val_loss: 6.6479 - val_mse: 6.6479\n",
      "Epoch 339/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 7.8890 - mse: 7.8890 - val_loss: 6.6494 - val_mse: 6.6494\n",
      "Epoch 340/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 7.8892 - mse: 7.8892 - val_loss: 6.6445 - val_mse: 6.6445\n",
      "Epoch 341/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 7.8931 - mse: 7.8931 - val_loss: 6.6411 - val_mse: 6.6411\n",
      "Epoch 342/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 7.8851 - mse: 7.8851 - val_loss: 6.6440 - val_mse: 6.6440\n",
      "Epoch 343/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 7.8755 - mse: 7.8755 - val_loss: 6.6352 - val_mse: 6.6352\n",
      "Epoch 344/1000\n",
      "128/128 [==============================] - 0s 438us/sample - loss: 7.8786 - mse: 7.8786 - val_loss: 6.6411 - val_mse: 6.6411\n",
      "Epoch 345/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 7.8681 - mse: 7.8681 - val_loss: 6.6347 - val_mse: 6.6347\n",
      "Epoch 346/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 7.8623 - mse: 7.8623 - val_loss: 6.6338 - val_mse: 6.6338\n",
      "Epoch 347/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 7.8645 - mse: 7.8645 - val_loss: 6.6304 - val_mse: 6.6304\n",
      "Epoch 348/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 7.8632 - mse: 7.8632 - val_loss: 6.6274 - val_mse: 6.6274\n",
      "Epoch 349/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 7.8527 - mse: 7.8527 - val_loss: 6.6248 - val_mse: 6.6248\n",
      "Epoch 350/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 7.8647 - mse: 7.8647 - val_loss: 6.6216 - val_mse: 6.6216\n",
      "Epoch 351/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 286us/sample - loss: 7.8506 - mse: 7.8506 - val_loss: 6.6153 - val_mse: 6.6153\n",
      "Epoch 352/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 7.8488 - mse: 7.8488 - val_loss: 6.6050 - val_mse: 6.6050\n",
      "Epoch 353/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 7.8419 - mse: 7.8419 - val_loss: 6.5984 - val_mse: 6.5984\n",
      "Epoch 354/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 7.8372 - mse: 7.8372 - val_loss: 6.6067 - val_mse: 6.6067\n",
      "Epoch 355/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 7.8392 - mse: 7.8392 - val_loss: 6.6061 - val_mse: 6.6061\n",
      "Epoch 356/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 7.8290 - mse: 7.8290 - val_loss: 6.5948 - val_mse: 6.5948\n",
      "Epoch 357/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 7.8237 - mse: 7.8237 - val_loss: 6.5997 - val_mse: 6.5997\n",
      "Epoch 358/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.8359 - mse: 7.8359 - val_loss: 6.6040 - val_mse: 6.6040\n",
      "Epoch 359/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 7.8241 - mse: 7.8241 - val_loss: 6.5920 - val_mse: 6.5920\n",
      "Epoch 360/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 7.8175 - mse: 7.8175 - val_loss: 6.5876 - val_mse: 6.5876\n",
      "Epoch 361/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 7.8168 - mse: 7.8168 - val_loss: 6.5802 - val_mse: 6.5802\n",
      "Epoch 362/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 7.8128 - mse: 7.8128 - val_loss: 6.5849 - val_mse: 6.5849\n",
      "Epoch 363/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 7.8041 - mse: 7.8041 - val_loss: 6.5752 - val_mse: 6.5752\n",
      "Epoch 364/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 7.8011 - mse: 7.8011 - val_loss: 6.5692 - val_mse: 6.5692\n",
      "Epoch 365/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 7.7968 - mse: 7.7968 - val_loss: 6.5618 - val_mse: 6.5618\n",
      "Epoch 366/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 7.7922 - mse: 7.7922 - val_loss: 6.5578 - val_mse: 6.5578\n",
      "Epoch 367/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 7.7952 - mse: 7.7952 - val_loss: 6.5605 - val_mse: 6.5605\n",
      "Epoch 368/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 7.7922 - mse: 7.7922 - val_loss: 6.5549 - val_mse: 6.5549\n",
      "Epoch 369/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 7.7862 - mse: 7.7862 - val_loss: 6.5506 - val_mse: 6.5506\n",
      "Epoch 370/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 7.7833 - mse: 7.7833 - val_loss: 6.5339 - val_mse: 6.5339\n",
      "Epoch 371/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 7.7808 - mse: 7.7808 - val_loss: 6.5315 - val_mse: 6.5315\n",
      "Epoch 372/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 7.7779 - mse: 7.7779 - val_loss: 6.5288 - val_mse: 6.5288\n",
      "Epoch 373/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 7.7758 - mse: 7.7758 - val_loss: 6.5411 - val_mse: 6.5411\n",
      "Epoch 374/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 7.7745 - mse: 7.7745 - val_loss: 6.5311 - val_mse: 6.5311\n",
      "Epoch 375/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 7.7681 - mse: 7.7681 - val_loss: 6.5287 - val_mse: 6.5287\n",
      "Epoch 376/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 7.7632 - mse: 7.7632 - val_loss: 6.5252 - val_mse: 6.5252\n",
      "Epoch 377/1000\n",
      "128/128 [==============================] - 0s 481us/sample - loss: 7.7588 - mse: 7.7588 - val_loss: 6.5330 - val_mse: 6.5330\n",
      "Epoch 378/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 7.7567 - mse: 7.7567 - val_loss: 6.5241 - val_mse: 6.5241\n",
      "Epoch 379/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 7.7563 - mse: 7.7563 - val_loss: 6.5220 - val_mse: 6.5220\n",
      "Epoch 380/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 7.7553 - mse: 7.7553 - val_loss: 6.5147 - val_mse: 6.5147\n",
      "Epoch 381/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 7.7453 - mse: 7.7453 - val_loss: 6.5230 - val_mse: 6.5230\n",
      "Epoch 382/1000\n",
      "128/128 [==============================] - 0s 398us/sample - loss: 7.7429 - mse: 7.7429 - val_loss: 6.5180 - val_mse: 6.5180\n",
      "Epoch 383/1000\n",
      "128/128 [==============================] - 0s 396us/sample - loss: 7.7395 - mse: 7.7395 - val_loss: 6.5198 - val_mse: 6.5198\n",
      "Epoch 384/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 7.7499 - mse: 7.7499 - val_loss: 6.5085 - val_mse: 6.5085\n",
      "Epoch 385/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 7.7294 - mse: 7.7294 - val_loss: 6.5022 - val_mse: 6.5022\n",
      "Epoch 386/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 7.7279 - mse: 7.7279 - val_loss: 6.4992 - val_mse: 6.4992\n",
      "Epoch 387/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 7.7247 - mse: 7.7247 - val_loss: 6.5058 - val_mse: 6.5058\n",
      "Epoch 388/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.7240 - mse: 7.7240 - val_loss: 6.4969 - val_mse: 6.4969\n",
      "Epoch 389/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 7.7190 - mse: 7.7190 - val_loss: 6.4908 - val_mse: 6.4908\n",
      "Epoch 390/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 7.7106 - mse: 7.7106 - val_loss: 6.4854 - val_mse: 6.4854\n",
      "Epoch 391/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 7.7179 - mse: 7.7179 - val_loss: 6.4882 - val_mse: 6.4882\n",
      "Epoch 392/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 7.7146 - mse: 7.7146 - val_loss: 6.4833 - val_mse: 6.4833\n",
      "Epoch 393/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 7.7051 - mse: 7.7051 - val_loss: 6.4739 - val_mse: 6.4739\n",
      "Epoch 394/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 7.6976 - mse: 7.6976 - val_loss: 6.4778 - val_mse: 6.4778\n",
      "Epoch 395/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 7.6982 - mse: 7.6982 - val_loss: 6.4780 - val_mse: 6.4780\n",
      "Epoch 396/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 7.6945 - mse: 7.6945 - val_loss: 6.4821 - val_mse: 6.4821\n",
      "Epoch 397/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 7.6904 - mse: 7.6904 - val_loss: 6.4673 - val_mse: 6.4673\n",
      "Epoch 398/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 7.6937 - mse: 7.6937 - val_loss: 6.4669 - val_mse: 6.4669\n",
      "Epoch 399/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 7.6898 - mse: 7.6898 - val_loss: 6.4569 - val_mse: 6.4569\n",
      "Epoch 400/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 7.6781 - mse: 7.6781 - val_loss: 6.4598 - val_mse: 6.4598\n",
      "Epoch 401/1000\n",
      "128/128 [==============================] - 0s 394us/sample - loss: 7.6730 - mse: 7.6730 - val_loss: 6.4589 - val_mse: 6.4589\n",
      "Epoch 402/1000\n",
      "128/128 [==============================] - 0s 416us/sample - loss: 7.6762 - mse: 7.6762 - val_loss: 6.4448 - val_mse: 6.4448\n",
      "Epoch 403/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 7.6753 - mse: 7.6753 - val_loss: 6.4333 - val_mse: 6.4333\n",
      "Epoch 404/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 7.6632 - mse: 7.6632 - val_loss: 6.4331 - val_mse: 6.4331\n",
      "Epoch 405/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 7.6575 - mse: 7.6575 - val_loss: 6.4295 - val_mse: 6.4295\n",
      "Epoch 406/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 7.6685 - mse: 7.6685 - val_loss: 6.4271 - val_mse: 6.4271\n",
      "Epoch 407/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 7.6592 - mse: 7.6592 - val_loss: 6.4223 - val_mse: 6.4223\n",
      "Epoch 408/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 7.6595 - mse: 7.6595 - val_loss: 6.4262 - val_mse: 6.4262\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 322us/sample - loss: 7.6520 - mse: 7.6520 - val_loss: 6.4276 - val_mse: 6.4276\n",
      "Epoch 410/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 7.6485 - mse: 7.6485 - val_loss: 6.4262 - val_mse: 6.4262\n",
      "Epoch 411/1000\n",
      "128/128 [==============================] - 0s 381us/sample - loss: 7.6426 - mse: 7.6426 - val_loss: 6.4281 - val_mse: 6.4281\n",
      "Epoch 412/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 7.6345 - mse: 7.6345 - val_loss: 6.4200 - val_mse: 6.4200\n",
      "Epoch 413/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 7.6319 - mse: 7.6319 - val_loss: 6.4216 - val_mse: 6.4216\n",
      "Epoch 414/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 7.6256 - mse: 7.6256 - val_loss: 6.4218 - val_mse: 6.4218\n",
      "Epoch 415/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 7.6287 - mse: 7.6287 - val_loss: 6.4179 - val_mse: 6.4179\n",
      "Epoch 416/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 7.6276 - mse: 7.6276 - val_loss: 6.4127 - val_mse: 6.4127\n",
      "Epoch 417/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 7.6233 - mse: 7.6233 - val_loss: 6.4052 - val_mse: 6.4052\n",
      "Epoch 418/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 7.6182 - mse: 7.6182 - val_loss: 6.3954 - val_mse: 6.3954\n",
      "Epoch 419/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 7.6166 - mse: 7.6166 - val_loss: 6.3906 - val_mse: 6.3906\n",
      "Epoch 420/1000\n",
      "128/128 [==============================] - 0s 364us/sample - loss: 7.6080 - mse: 7.6080 - val_loss: 6.3913 - val_mse: 6.3913\n",
      "Epoch 421/1000\n",
      "128/128 [==============================] - 0s 259us/sample - loss: 7.6117 - mse: 7.6117 - val_loss: 6.3931 - val_mse: 6.3931\n",
      "Epoch 422/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 7.6058 - mse: 7.6058 - val_loss: 6.3950 - val_mse: 6.3950\n",
      "Epoch 423/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 7.6033 - mse: 7.6033 - val_loss: 6.3924 - val_mse: 6.3924\n",
      "Epoch 424/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 7.5935 - mse: 7.5935 - val_loss: 6.3872 - val_mse: 6.3872\n",
      "Epoch 425/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 7.5924 - mse: 7.5924 - val_loss: 6.3838 - val_mse: 6.3838\n",
      "Epoch 426/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 7.5898 - mse: 7.5898 - val_loss: 6.3848 - val_mse: 6.3848\n",
      "Epoch 427/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 7.5842 - mse: 7.5842 - val_loss: 6.3832 - val_mse: 6.3832\n",
      "Epoch 428/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 7.5943 - mse: 7.5943 - val_loss: 6.3709 - val_mse: 6.3709\n",
      "Epoch 429/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 7.5825 - mse: 7.5825 - val_loss: 6.3676 - val_mse: 6.3676\n",
      "Epoch 430/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 7.5775 - mse: 7.5775 - val_loss: 6.3665 - val_mse: 6.3665\n",
      "Epoch 431/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 7.5705 - mse: 7.5705 - val_loss: 6.3635 - val_mse: 6.3635\n",
      "Epoch 432/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 7.5798 - mse: 7.5798 - val_loss: 6.3568 - val_mse: 6.3568\n",
      "Epoch 433/1000\n",
      "128/128 [==============================] - 0s 383us/sample - loss: 7.5656 - mse: 7.5656 - val_loss: 6.3494 - val_mse: 6.3494\n",
      "Epoch 434/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 7.5662 - mse: 7.5662 - val_loss: 6.3485 - val_mse: 6.3485\n",
      "Epoch 435/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 7.5591 - mse: 7.5591 - val_loss: 6.3424 - val_mse: 6.3424\n",
      "Epoch 436/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 7.5624 - mse: 7.5624 - val_loss: 6.3363 - val_mse: 6.3363\n",
      "Epoch 437/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 7.5534 - mse: 7.5534 - val_loss: 6.3333 - val_mse: 6.3333\n",
      "Epoch 438/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 7.5478 - mse: 7.5478 - val_loss: 6.3302 - val_mse: 6.3302\n",
      "Epoch 439/1000\n",
      "128/128 [==============================] - 0s 383us/sample - loss: 7.5529 - mse: 7.5529 - val_loss: 6.3326 - val_mse: 6.3326\n",
      "Epoch 440/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 7.5479 - mse: 7.5479 - val_loss: 6.3235 - val_mse: 6.3235\n",
      "Epoch 441/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 7.5449 - mse: 7.5449 - val_loss: 6.3313 - val_mse: 6.3313\n",
      "Epoch 442/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 7.5335 - mse: 7.5335 - val_loss: 6.3336 - val_mse: 6.3336\n",
      "Epoch 443/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 7.5371 - mse: 7.5371 - val_loss: 6.3387 - val_mse: 6.3387\n",
      "Epoch 444/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 7.5331 - mse: 7.5331 - val_loss: 6.3350 - val_mse: 6.3350\n",
      "Epoch 445/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 7.5350 - mse: 7.5350 - val_loss: 6.3210 - val_mse: 6.3210\n",
      "Epoch 446/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 7.5261 - mse: 7.5261 - val_loss: 6.3162 - val_mse: 6.3162\n",
      "Epoch 447/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 7.5177 - mse: 7.5177 - val_loss: 6.3142 - val_mse: 6.3142\n",
      "Epoch 448/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 7.5161 - mse: 7.5161 - val_loss: 6.3087 - val_mse: 6.3087\n",
      "Epoch 449/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 7.5251 - mse: 7.5251 - val_loss: 6.3089 - val_mse: 6.3089\n",
      "Epoch 450/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 7.5148 - mse: 7.5148 - val_loss: 6.2994 - val_mse: 6.2994\n",
      "Epoch 451/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 7.5089 - mse: 7.5089 - val_loss: 6.3036 - val_mse: 6.3036\n",
      "Epoch 452/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 7.5029 - mse: 7.5029 - val_loss: 6.2965 - val_mse: 6.2965\n",
      "Epoch 453/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 7.5086 - mse: 7.5086 - val_loss: 6.2935 - val_mse: 6.2935\n",
      "Epoch 454/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 7.4984 - mse: 7.4984 - val_loss: 6.2857 - val_mse: 6.2857\n",
      "Epoch 455/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 7.4921 - mse: 7.4921 - val_loss: 6.2845 - val_mse: 6.2845\n",
      "Epoch 456/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 7.4932 - mse: 7.4932 - val_loss: 6.2904 - val_mse: 6.2904\n",
      "Epoch 457/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 7.4936 - mse: 7.4936 - val_loss: 6.2819 - val_mse: 6.2819\n",
      "Epoch 458/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 7.4929 - mse: 7.4929 - val_loss: 6.2791 - val_mse: 6.2791\n",
      "Epoch 459/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 7.4814 - mse: 7.4814 - val_loss: 6.2748 - val_mse: 6.2748\n",
      "Epoch 460/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 7.4752 - mse: 7.4752 - val_loss: 6.2762 - val_mse: 6.2762\n",
      "Epoch 461/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 7.4701 - mse: 7.4701 - val_loss: 6.2700 - val_mse: 6.2700\n",
      "Epoch 462/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 7.4792 - mse: 7.4792 - val_loss: 6.2660 - val_mse: 6.2660\n",
      "Epoch 463/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 7.4732 - mse: 7.4732 - val_loss: 6.2614 - val_mse: 6.2614\n",
      "Epoch 464/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 7.4678 - mse: 7.4678 - val_loss: 6.2618 - val_mse: 6.2618\n",
      "Epoch 465/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 7.4613 - mse: 7.4613 - val_loss: 6.2639 - val_mse: 6.2639\n",
      "Epoch 466/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 7.4631 - mse: 7.4631 - val_loss: 6.2656 - val_mse: 6.2656\n",
      "Epoch 467/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 318us/sample - loss: 7.4573 - mse: 7.4573 - val_loss: 6.2573 - val_mse: 6.2573\n",
      "Epoch 468/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 7.4555 - mse: 7.4555 - val_loss: 6.2607 - val_mse: 6.2607\n",
      "Epoch 469/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 7.4480 - mse: 7.4480 - val_loss: 6.2539 - val_mse: 6.2539\n",
      "Epoch 470/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 7.4473 - mse: 7.4473 - val_loss: 6.2567 - val_mse: 6.2567\n",
      "Epoch 471/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 7.4378 - mse: 7.4378 - val_loss: 6.2577 - val_mse: 6.2577\n",
      "Epoch 472/1000\n",
      "128/128 [==============================] - 0s 352us/sample - loss: 7.4387 - mse: 7.4387 - val_loss: 6.2583 - val_mse: 6.2583\n",
      "Epoch 473/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 7.4354 - mse: 7.4354 - val_loss: 6.2498 - val_mse: 6.2498\n",
      "Epoch 474/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 7.4360 - mse: 7.4360 - val_loss: 6.2351 - val_mse: 6.2351\n",
      "Epoch 475/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 7.4247 - mse: 7.4247 - val_loss: 6.2273 - val_mse: 6.2273\n",
      "Epoch 476/1000\n",
      "128/128 [==============================] - 0s 408us/sample - loss: 7.4265 - mse: 7.4265 - val_loss: 6.2221 - val_mse: 6.2221\n",
      "Epoch 477/1000\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 7.4225 - mse: 7.4225 - val_loss: 6.2103 - val_mse: 6.2103\n",
      "Epoch 478/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 7.4218 - mse: 7.4218 - val_loss: 6.2120 - val_mse: 6.2120\n",
      "Epoch 479/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 7.4162 - mse: 7.4162 - val_loss: 6.2083 - val_mse: 6.2083\n",
      "Epoch 480/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 7.4149 - mse: 7.4149 - val_loss: 6.2038 - val_mse: 6.2038\n",
      "Epoch 481/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 7.4140 - mse: 7.4140 - val_loss: 6.2084 - val_mse: 6.2084\n",
      "Epoch 482/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 7.4095 - mse: 7.4095 - val_loss: 6.2048 - val_mse: 6.2048\n",
      "Epoch 483/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 7.4012 - mse: 7.4012 - val_loss: 6.2117 - val_mse: 6.2117\n",
      "Epoch 484/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 7.3979 - mse: 7.3979 - val_loss: 6.2112 - val_mse: 6.2112\n",
      "Epoch 485/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 7.3960 - mse: 7.3960 - val_loss: 6.2079 - val_mse: 6.2079\n",
      "Epoch 486/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 7.3895 - mse: 7.3895 - val_loss: 6.1990 - val_mse: 6.1990\n",
      "Epoch 487/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 7.3909 - mse: 7.3909 - val_loss: 6.1963 - val_mse: 6.1963\n",
      "Epoch 488/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 7.3881 - mse: 7.3881 - val_loss: 6.1966 - val_mse: 6.1966\n",
      "Epoch 489/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 7.3829 - mse: 7.3829 - val_loss: 6.1874 - val_mse: 6.1874\n",
      "Epoch 490/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.3810 - mse: 7.3810 - val_loss: 6.1886 - val_mse: 6.1886\n",
      "Epoch 491/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 7.3801 - mse: 7.3801 - val_loss: 6.1892 - val_mse: 6.1892\n",
      "Epoch 492/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 7.3759 - mse: 7.3759 - val_loss: 6.1792 - val_mse: 6.1792\n",
      "Epoch 493/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 7.3701 - mse: 7.3701 - val_loss: 6.1807 - val_mse: 6.1807\n",
      "Epoch 494/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 7.3631 - mse: 7.3631 - val_loss: 6.1782 - val_mse: 6.1782\n",
      "Epoch 495/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 7.3666 - mse: 7.3666 - val_loss: 6.1732 - val_mse: 6.1732\n",
      "Epoch 496/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 7.3601 - mse: 7.3601 - val_loss: 6.1725 - val_mse: 6.1725\n",
      "Epoch 497/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 7.3579 - mse: 7.3579 - val_loss: 6.1694 - val_mse: 6.1694\n",
      "Epoch 498/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 7.3504 - mse: 7.3504 - val_loss: 6.1634 - val_mse: 6.1634\n",
      "Epoch 499/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 7.3530 - mse: 7.3530 - val_loss: 6.1557 - val_mse: 6.1557\n",
      "Epoch 500/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 7.3555 - mse: 7.3555 - val_loss: 6.1525 - val_mse: 6.1525\n",
      "Epoch 501/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 7.3500 - mse: 7.3500 - val_loss: 6.1478 - val_mse: 6.1478\n",
      "Epoch 502/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 7.3441 - mse: 7.3441 - val_loss: 6.1586 - val_mse: 6.1586\n",
      "Epoch 503/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 7.3411 - mse: 7.3411 - val_loss: 6.1432 - val_mse: 6.1432\n",
      "Epoch 504/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 7.3353 - mse: 7.3353 - val_loss: 6.1348 - val_mse: 6.1348\n",
      "Epoch 505/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.3274 - mse: 7.3274 - val_loss: 6.1441 - val_mse: 6.1441\n",
      "Epoch 506/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 7.3342 - mse: 7.3342 - val_loss: 6.1325 - val_mse: 6.1325\n",
      "Epoch 507/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 7.3266 - mse: 7.3266 - val_loss: 6.1316 - val_mse: 6.1316\n",
      "Epoch 508/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 7.3217 - mse: 7.3217 - val_loss: 6.1292 - val_mse: 6.1292\n",
      "Epoch 509/1000\n",
      "128/128 [==============================] - 0s 434us/sample - loss: 7.3234 - mse: 7.3234 - val_loss: 6.1393 - val_mse: 6.1393\n",
      "Epoch 510/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 7.3165 - mse: 7.3165 - val_loss: 6.1364 - val_mse: 6.1364\n",
      "Epoch 511/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 7.3131 - mse: 7.3131 - val_loss: 6.1347 - val_mse: 6.1347\n",
      "Epoch 512/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 7.3108 - mse: 7.3108 - val_loss: 6.1361 - val_mse: 6.1361\n",
      "Epoch 513/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 7.3089 - mse: 7.3089 - val_loss: 6.1249 - val_mse: 6.1249\n",
      "Epoch 514/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 7.3022 - mse: 7.3022 - val_loss: 6.1181 - val_mse: 6.1181\n",
      "Epoch 515/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 7.2984 - mse: 7.2984 - val_loss: 6.1140 - val_mse: 6.1140\n",
      "Epoch 516/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 7.2982 - mse: 7.2982 - val_loss: 6.1080 - val_mse: 6.1080\n",
      "Epoch 517/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 7.2972 - mse: 7.2972 - val_loss: 6.1114 - val_mse: 6.1114\n",
      "Epoch 518/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 7.2923 - mse: 7.2923 - val_loss: 6.1084 - val_mse: 6.1084\n",
      "Epoch 519/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 7.2859 - mse: 7.2859 - val_loss: 6.1104 - val_mse: 6.1104\n",
      "Epoch 520/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 7.2932 - mse: 7.2932 - val_loss: 6.1000 - val_mse: 6.1000\n",
      "Epoch 521/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 7.2831 - mse: 7.2831 - val_loss: 6.0956 - val_mse: 6.0956\n",
      "Epoch 522/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 7.2733 - mse: 7.2733 - val_loss: 6.0935 - val_mse: 6.0935\n",
      "Epoch 523/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 7.2727 - mse: 7.2727 - val_loss: 6.0956 - val_mse: 6.0956\n",
      "Epoch 524/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 7.2708 - mse: 7.2708 - val_loss: 6.0896 - val_mse: 6.0896\n",
      "Epoch 525/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 317us/sample - loss: 7.2682 - mse: 7.2682 - val_loss: 6.0858 - val_mse: 6.0858\n",
      "Epoch 526/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 7.2601 - mse: 7.2601 - val_loss: 6.0858 - val_mse: 6.0858\n",
      "Epoch 527/1000\n",
      "128/128 [==============================] - 0s 410us/sample - loss: 7.2602 - mse: 7.2602 - val_loss: 6.0834 - val_mse: 6.0834\n",
      "Epoch 528/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 7.2596 - mse: 7.2596 - val_loss: 6.0814 - val_mse: 6.0814\n",
      "Epoch 529/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 7.2535 - mse: 7.2535 - val_loss: 6.0780 - val_mse: 6.0780\n",
      "Epoch 530/1000\n",
      "128/128 [==============================] - 0s 260us/sample - loss: 7.2484 - mse: 7.2484 - val_loss: 6.0708 - val_mse: 6.0708\n",
      "Epoch 531/1000\n",
      "128/128 [==============================] - 0s 269us/sample - loss: 7.2561 - mse: 7.2561 - val_loss: 6.0671 - val_mse: 6.0672\n",
      "Epoch 532/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 7.2466 - mse: 7.2466 - val_loss: 6.0635 - val_mse: 6.0635\n",
      "Epoch 533/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 7.2399 - mse: 7.2399 - val_loss: 6.0656 - val_mse: 6.0656\n",
      "Epoch 534/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 7.2364 - mse: 7.2364 - val_loss: 6.0620 - val_mse: 6.0620\n",
      "Epoch 535/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 7.2434 - mse: 7.2434 - val_loss: 6.0509 - val_mse: 6.0509\n",
      "Epoch 536/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 7.2382 - mse: 7.2382 - val_loss: 6.0546 - val_mse: 6.0546\n",
      "Epoch 537/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 7.2312 - mse: 7.2312 - val_loss: 6.0498 - val_mse: 6.0498\n",
      "Epoch 538/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 7.2268 - mse: 7.2268 - val_loss: 6.0529 - val_mse: 6.0529\n",
      "Epoch 539/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 7.2250 - mse: 7.2250 - val_loss: 6.0575 - val_mse: 6.0575\n",
      "Epoch 540/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 7.2194 - mse: 7.2194 - val_loss: 6.0559 - val_mse: 6.0559\n",
      "Epoch 541/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 7.2238 - mse: 7.2238 - val_loss: 6.0442 - val_mse: 6.0442\n",
      "Epoch 542/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 7.2164 - mse: 7.2164 - val_loss: 6.0401 - val_mse: 6.0401\n",
      "Epoch 543/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 7.2068 - mse: 7.2068 - val_loss: 6.0364 - val_mse: 6.0364\n",
      "Epoch 544/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 7.2047 - mse: 7.2047 - val_loss: 6.0287 - val_mse: 6.0287\n",
      "Epoch 545/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 7.2033 - mse: 7.2033 - val_loss: 6.0311 - val_mse: 6.0311\n",
      "Epoch 546/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 7.2008 - mse: 7.2008 - val_loss: 6.0297 - val_mse: 6.0297\n",
      "Epoch 547/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 7.2024 - mse: 7.2024 - val_loss: 6.0180 - val_mse: 6.0180\n",
      "Epoch 548/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 7.1906 - mse: 7.1906 - val_loss: 6.0125 - val_mse: 6.0125\n",
      "Epoch 549/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 7.1886 - mse: 7.1886 - val_loss: 6.0060 - val_mse: 6.0060\n",
      "Epoch 550/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 7.1909 - mse: 7.1909 - val_loss: 6.0090 - val_mse: 6.0090\n",
      "Epoch 551/1000\n",
      "128/128 [==============================] - 0s 240us/sample - loss: 7.1860 - mse: 7.1860 - val_loss: 6.0069 - val_mse: 6.0069\n",
      "Epoch 552/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 7.1883 - mse: 7.1883 - val_loss: 6.0089 - val_mse: 6.0089\n",
      "Epoch 553/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 7.1772 - mse: 7.1772 - val_loss: 6.0099 - val_mse: 6.0099\n",
      "Epoch 554/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 7.1775 - mse: 7.1775 - val_loss: 6.0038 - val_mse: 6.0038\n",
      "Epoch 555/1000\n",
      "128/128 [==============================] - 0s 391us/sample - loss: 7.1734 - mse: 7.1734 - val_loss: 5.9955 - val_mse: 5.9955\n",
      "Epoch 556/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 7.1653 - mse: 7.1653 - val_loss: 5.9934 - val_mse: 5.9934\n",
      "Epoch 557/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 7.1682 - mse: 7.1682 - val_loss: 5.9950 - val_mse: 5.9950\n",
      "Epoch 558/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 7.1641 - mse: 7.1641 - val_loss: 5.9940 - val_mse: 5.9940\n",
      "Epoch 559/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 7.1641 - mse: 7.1641 - val_loss: 5.9979 - val_mse: 5.9979\n",
      "Epoch 560/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 7.1543 - mse: 7.1543 - val_loss: 5.9933 - val_mse: 5.9933\n",
      "Epoch 561/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 7.1579 - mse: 7.1579 - val_loss: 5.9931 - val_mse: 5.9931\n",
      "Epoch 562/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 7.1580 - mse: 7.1580 - val_loss: 5.9974 - val_mse: 5.9974\n",
      "Epoch 563/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.1485 - mse: 7.1485 - val_loss: 5.9963 - val_mse: 5.9963\n",
      "Epoch 564/1000\n",
      "128/128 [==============================] - 0s 370us/sample - loss: 7.1410 - mse: 7.1410 - val_loss: 5.9876 - val_mse: 5.9876\n",
      "Epoch 565/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 7.1375 - mse: 7.1375 - val_loss: 5.9901 - val_mse: 5.9901\n",
      "Epoch 566/1000\n",
      "128/128 [==============================] - 0s 364us/sample - loss: 7.1454 - mse: 7.1454 - val_loss: 5.9900 - val_mse: 5.9900\n",
      "Epoch 567/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 7.1377 - mse: 7.1377 - val_loss: 5.9839 - val_mse: 5.9839\n",
      "Epoch 568/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 7.1308 - mse: 7.1308 - val_loss: 5.9781 - val_mse: 5.9781\n",
      "Epoch 569/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 7.1291 - mse: 7.1291 - val_loss: 5.9755 - val_mse: 5.9755\n",
      "Epoch 570/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 7.1275 - mse: 7.1275 - val_loss: 5.9647 - val_mse: 5.9647\n",
      "Epoch 571/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 7.1277 - mse: 7.1277 - val_loss: 5.9572 - val_mse: 5.9572\n",
      "Epoch 572/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 7.1219 - mse: 7.1219 - val_loss: 5.9593 - val_mse: 5.9593\n",
      "Epoch 573/1000\n",
      "128/128 [==============================] - 0s 424us/sample - loss: 7.1162 - mse: 7.1162 - val_loss: 5.9506 - val_mse: 5.9506\n",
      "Epoch 574/1000\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 7.1171 - mse: 7.1171 - val_loss: 5.9444 - val_mse: 5.9444\n",
      "Epoch 575/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 7.1090 - mse: 7.1090 - val_loss: 5.9392 - val_mse: 5.9392\n",
      "Epoch 576/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 7.1131 - mse: 7.1131 - val_loss: 5.9323 - val_mse: 5.9323\n",
      "Epoch 577/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 7.1060 - mse: 7.1060 - val_loss: 5.9277 - val_mse: 5.9277\n",
      "Epoch 578/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 7.0980 - mse: 7.0980 - val_loss: 5.9272 - val_mse: 5.9272\n",
      "Epoch 579/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 7.1051 - mse: 7.1051 - val_loss: 5.9275 - val_mse: 5.9275\n",
      "Epoch 580/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 7.0887 - mse: 7.0887 - val_loss: 5.9248 - val_mse: 5.9248\n",
      "Epoch 581/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 7.1000 - mse: 7.1000 - val_loss: 5.9195 - val_mse: 5.9195\n",
      "Epoch 582/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 7.0923 - mse: 7.0923 - val_loss: 5.9139 - val_mse: 5.9139\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 331us/sample - loss: 7.0839 - mse: 7.0839 - val_loss: 5.9105 - val_mse: 5.9105\n",
      "Epoch 584/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 7.0822 - mse: 7.0822 - val_loss: 5.9041 - val_mse: 5.9041\n",
      "Epoch 585/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 7.0778 - mse: 7.0778 - val_loss: 5.9037 - val_mse: 5.9037\n",
      "Epoch 586/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 7.0774 - mse: 7.0774 - val_loss: 5.9120 - val_mse: 5.9120\n",
      "Epoch 587/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 7.0714 - mse: 7.0714 - val_loss: 5.9084 - val_mse: 5.9084\n",
      "Epoch 588/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 7.0713 - mse: 7.0713 - val_loss: 5.9074 - val_mse: 5.9074\n",
      "Epoch 589/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 7.0632 - mse: 7.0632 - val_loss: 5.9101 - val_mse: 5.9101\n",
      "Epoch 590/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 7.0626 - mse: 7.0626 - val_loss: 5.9045 - val_mse: 5.9045\n",
      "Epoch 591/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 7.0613 - mse: 7.0613 - val_loss: 5.9019 - val_mse: 5.9019\n",
      "Epoch 592/1000\n",
      "128/128 [==============================] - 0s 401us/sample - loss: 7.0570 - mse: 7.0570 - val_loss: 5.8985 - val_mse: 5.8985\n",
      "Epoch 593/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 7.0496 - mse: 7.0496 - val_loss: 5.8957 - val_mse: 5.8957\n",
      "Epoch 594/1000\n",
      "128/128 [==============================] - 0s 469us/sample - loss: 7.0481 - mse: 7.0481 - val_loss: 5.8912 - val_mse: 5.8912\n",
      "Epoch 595/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 7.0474 - mse: 7.0474 - val_loss: 5.8922 - val_mse: 5.8922\n",
      "Epoch 596/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 7.0461 - mse: 7.0461 - val_loss: 5.8899 - val_mse: 5.8899\n",
      "Epoch 597/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 7.0419 - mse: 7.0419 - val_loss: 5.8811 - val_mse: 5.8811\n",
      "Epoch 598/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 7.0356 - mse: 7.0356 - val_loss: 5.8732 - val_mse: 5.8732\n",
      "Epoch 599/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 7.0317 - mse: 7.0317 - val_loss: 5.8720 - val_mse: 5.8720\n",
      "Epoch 600/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 7.0370 - mse: 7.0370 - val_loss: 5.8741 - val_mse: 5.8741\n",
      "Epoch 601/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 7.0326 - mse: 7.0326 - val_loss: 5.8705 - val_mse: 5.8705\n",
      "Epoch 602/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 7.0285 - mse: 7.0285 - val_loss: 5.8740 - val_mse: 5.8740\n",
      "Epoch 603/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 7.0211 - mse: 7.0211 - val_loss: 5.8664 - val_mse: 5.8664\n",
      "Epoch 604/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 7.0212 - mse: 7.0212 - val_loss: 5.8540 - val_mse: 5.8540\n",
      "Epoch 605/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 7.0185 - mse: 7.0185 - val_loss: 5.8555 - val_mse: 5.8555\n",
      "Epoch 606/1000\n",
      "128/128 [==============================] - 0s 364us/sample - loss: 7.0169 - mse: 7.0169 - val_loss: 5.8492 - val_mse: 5.8492\n",
      "Epoch 607/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 7.0089 - mse: 7.0089 - val_loss: 5.8474 - val_mse: 5.8474\n",
      "Epoch 608/1000\n",
      "128/128 [==============================] - 0s 269us/sample - loss: 7.0072 - mse: 7.0072 - val_loss: 5.8419 - val_mse: 5.8419\n",
      "Epoch 609/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 7.0063 - mse: 7.0063 - val_loss: 5.8385 - val_mse: 5.8385\n",
      "Epoch 610/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 7.0027 - mse: 7.0027 - val_loss: 5.8369 - val_mse: 5.8369\n",
      "Epoch 611/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 7.0018 - mse: 7.0018 - val_loss: 5.8344 - val_mse: 5.8344\n",
      "Epoch 612/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.9931 - mse: 6.9931 - val_loss: 5.8271 - val_mse: 5.8271\n",
      "Epoch 613/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 6.9948 - mse: 6.9948 - val_loss: 5.8316 - val_mse: 5.8316\n",
      "Epoch 614/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 6.9897 - mse: 6.9897 - val_loss: 5.8283 - val_mse: 5.8283\n",
      "Epoch 615/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 6.9905 - mse: 6.9905 - val_loss: 5.8285 - val_mse: 5.8285\n",
      "Epoch 616/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 6.9824 - mse: 6.9824 - val_loss: 5.8251 - val_mse: 5.8251\n",
      "Epoch 617/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 6.9787 - mse: 6.9787 - val_loss: 5.8225 - val_mse: 5.8225\n",
      "Epoch 618/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 6.9794 - mse: 6.9794 - val_loss: 5.8245 - val_mse: 5.8245\n",
      "Epoch 619/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 6.9766 - mse: 6.9766 - val_loss: 5.8178 - val_mse: 5.8178\n",
      "Epoch 620/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 6.9750 - mse: 6.9750 - val_loss: 5.8127 - val_mse: 5.8127\n",
      "Epoch 621/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 6.9644 - mse: 6.9644 - val_loss: 5.8087 - val_mse: 5.8087\n",
      "Epoch 622/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 6.9631 - mse: 6.9631 - val_loss: 5.8113 - val_mse: 5.8113\n",
      "Epoch 623/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 6.9667 - mse: 6.9667 - val_loss: 5.8134 - val_mse: 5.8134\n",
      "Epoch 624/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 6.9615 - mse: 6.9615 - val_loss: 5.8111 - val_mse: 5.8111\n",
      "Epoch 625/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 6.9566 - mse: 6.9566 - val_loss: 5.8133 - val_mse: 5.8133\n",
      "Epoch 626/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 6.9639 - mse: 6.9639 - val_loss: 5.7995 - val_mse: 5.7995\n",
      "Epoch 627/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 6.9576 - mse: 6.9576 - val_loss: 5.7903 - val_mse: 5.7903\n",
      "Epoch 628/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 6.9510 - mse: 6.9510 - val_loss: 5.7996 - val_mse: 5.7996\n",
      "Epoch 629/1000\n",
      "128/128 [==============================] - 0s 418us/sample - loss: 6.9449 - mse: 6.9449 - val_loss: 5.7951 - val_mse: 5.7951\n",
      "Epoch 630/1000\n",
      "128/128 [==============================] - 0s 396us/sample - loss: 6.9421 - mse: 6.9421 - val_loss: 5.7894 - val_mse: 5.7894\n",
      "Epoch 631/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 6.9357 - mse: 6.9357 - val_loss: 5.7923 - val_mse: 5.7923\n",
      "Epoch 632/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 6.9406 - mse: 6.9406 - val_loss: 5.7920 - val_mse: 5.7920\n",
      "Epoch 633/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 6.9319 - mse: 6.9319 - val_loss: 5.7906 - val_mse: 5.7906\n",
      "Epoch 634/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 6.9262 - mse: 6.9262 - val_loss: 5.7989 - val_mse: 5.7989\n",
      "Epoch 635/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 6.9258 - mse: 6.9258 - val_loss: 5.7831 - val_mse: 5.7831\n",
      "Epoch 636/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 6.9201 - mse: 6.9201 - val_loss: 5.7794 - val_mse: 5.7794\n",
      "Epoch 637/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 6.9228 - mse: 6.9228 - val_loss: 5.7758 - val_mse: 5.7758\n",
      "Epoch 638/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.9156 - mse: 6.9156 - val_loss: 5.7705 - val_mse: 5.7705\n",
      "Epoch 639/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 6.9201 - mse: 6.9201 - val_loss: 5.7726 - val_mse: 5.7726\n",
      "Epoch 640/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 6.9058 - mse: 6.9058 - val_loss: 5.7729 - val_mse: 5.7729\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 381us/sample - loss: 6.9039 - mse: 6.9039 - val_loss: 5.7637 - val_mse: 5.7637\n",
      "Epoch 642/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 6.9015 - mse: 6.9015 - val_loss: 5.7539 - val_mse: 5.7539\n",
      "Epoch 643/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 6.9025 - mse: 6.9025 - val_loss: 5.7502 - val_mse: 5.7502\n",
      "Epoch 644/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 6.8959 - mse: 6.8959 - val_loss: 5.7540 - val_mse: 5.7540\n",
      "Epoch 645/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 6.8960 - mse: 6.8960 - val_loss: 5.7436 - val_mse: 5.7436\n",
      "Epoch 646/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 6.8907 - mse: 6.8907 - val_loss: 5.7406 - val_mse: 5.7406\n",
      "Epoch 647/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 6.8881 - mse: 6.8881 - val_loss: 5.7410 - val_mse: 5.7410\n",
      "Epoch 648/1000\n",
      "128/128 [==============================] - 0s 352us/sample - loss: 6.8833 - mse: 6.8833 - val_loss: 5.7380 - val_mse: 5.7380\n",
      "Epoch 649/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 6.8847 - mse: 6.8847 - val_loss: 5.7436 - val_mse: 5.7436\n",
      "Epoch 650/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 6.8807 - mse: 6.8807 - val_loss: 5.7372 - val_mse: 5.7372\n",
      "Epoch 651/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 6.8784 - mse: 6.8784 - val_loss: 5.7364 - val_mse: 5.7364\n",
      "Epoch 652/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 6.8737 - mse: 6.8737 - val_loss: 5.7310 - val_mse: 5.7310\n",
      "Epoch 653/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 6.8680 - mse: 6.8680 - val_loss: 5.7261 - val_mse: 5.7261\n",
      "Epoch 654/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 6.8704 - mse: 6.8704 - val_loss: 5.7253 - val_mse: 5.7253\n",
      "Epoch 655/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 6.8615 - mse: 6.8615 - val_loss: 5.7244 - val_mse: 5.7244\n",
      "Epoch 656/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 6.8591 - mse: 6.8591 - val_loss: 5.7172 - val_mse: 5.7172\n",
      "Epoch 657/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 6.8603 - mse: 6.8603 - val_loss: 5.7135 - val_mse: 5.7135\n",
      "Epoch 658/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 6.8556 - mse: 6.8556 - val_loss: 5.7118 - val_mse: 5.7118\n",
      "Epoch 659/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 6.8526 - mse: 6.8526 - val_loss: 5.7101 - val_mse: 5.7101\n",
      "Epoch 660/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 6.8571 - mse: 6.8571 - val_loss: 5.7087 - val_mse: 5.7087\n",
      "Epoch 661/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 6.8502 - mse: 6.8502 - val_loss: 5.7011 - val_mse: 5.7011\n",
      "Epoch 662/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 6.8452 - mse: 6.8452 - val_loss: 5.6991 - val_mse: 5.6991\n",
      "Epoch 663/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 6.8411 - mse: 6.8411 - val_loss: 5.7016 - val_mse: 5.7016\n",
      "Epoch 664/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 6.8341 - mse: 6.8341 - val_loss: 5.6974 - val_mse: 5.6974\n",
      "Epoch 665/1000\n",
      "128/128 [==============================] - 0s 261us/sample - loss: 6.8392 - mse: 6.8392 - val_loss: 5.6893 - val_mse: 5.6892\n",
      "Epoch 666/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 6.8297 - mse: 6.8297 - val_loss: 5.6821 - val_mse: 5.6821\n",
      "Epoch 667/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 6.8288 - mse: 6.8288 - val_loss: 5.6784 - val_mse: 5.6784\n",
      "Epoch 668/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 6.8251 - mse: 6.8251 - val_loss: 5.6752 - val_mse: 5.6752\n",
      "Epoch 669/1000\n",
      "128/128 [==============================] - 0s 370us/sample - loss: 6.8233 - mse: 6.8233 - val_loss: 5.6767 - val_mse: 5.6767\n",
      "Epoch 670/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 6.8183 - mse: 6.8183 - val_loss: 5.6750 - val_mse: 5.6750\n",
      "Epoch 671/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 6.8210 - mse: 6.8210 - val_loss: 5.6777 - val_mse: 5.6777\n",
      "Epoch 672/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 6.8144 - mse: 6.8144 - val_loss: 5.6835 - val_mse: 5.6835\n",
      "Epoch 673/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 6.8130 - mse: 6.8130 - val_loss: 5.6705 - val_mse: 5.6705\n",
      "Epoch 674/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 6.8121 - mse: 6.8121 - val_loss: 5.6636 - val_mse: 5.6636\n",
      "Epoch 675/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 6.8114 - mse: 6.8114 - val_loss: 5.6589 - val_mse: 5.6589\n",
      "Epoch 676/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 6.8017 - mse: 6.8017 - val_loss: 5.6541 - val_mse: 5.6541\n",
      "Epoch 677/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 6.8004 - mse: 6.8004 - val_loss: 5.6554 - val_mse: 5.6554\n",
      "Epoch 678/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.7999 - mse: 6.7999 - val_loss: 5.6608 - val_mse: 5.6608\n",
      "Epoch 679/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 6.7897 - mse: 6.7897 - val_loss: 5.6643 - val_mse: 5.6643\n",
      "Epoch 680/1000\n",
      "128/128 [==============================] - 0s 420us/sample - loss: 6.7895 - mse: 6.7895 - val_loss: 5.6517 - val_mse: 5.6517\n",
      "Epoch 681/1000\n",
      "128/128 [==============================] - 0s 377us/sample - loss: 6.7835 - mse: 6.7835 - val_loss: 5.6521 - val_mse: 5.6521\n",
      "Epoch 682/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 6.7855 - mse: 6.7854 - val_loss: 5.6503 - val_mse: 5.6503\n",
      "Epoch 683/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 6.7845 - mse: 6.7845 - val_loss: 5.6441 - val_mse: 5.6441\n",
      "Epoch 684/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 6.7813 - mse: 6.7813 - val_loss: 5.6491 - val_mse: 5.6491\n",
      "Epoch 685/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 6.7752 - mse: 6.7752 - val_loss: 5.6384 - val_mse: 5.6384\n",
      "Epoch 686/1000\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 6.7719 - mse: 6.7719 - val_loss: 5.6419 - val_mse: 5.6419\n",
      "Epoch 687/1000\n",
      "128/128 [==============================] - 0s 377us/sample - loss: 6.7681 - mse: 6.7681 - val_loss: 5.6311 - val_mse: 5.6311\n",
      "Epoch 688/1000\n",
      "128/128 [==============================] - 0s 371us/sample - loss: 6.7683 - mse: 6.7683 - val_loss: 5.6260 - val_mse: 5.6260\n",
      "Epoch 689/1000\n",
      "128/128 [==============================] - 0s 388us/sample - loss: 6.7653 - mse: 6.7653 - val_loss: 5.6301 - val_mse: 5.6301\n",
      "Epoch 690/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 6.7598 - mse: 6.7598 - val_loss: 5.6318 - val_mse: 5.6318\n",
      "Epoch 691/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 6.7595 - mse: 6.7595 - val_loss: 5.6280 - val_mse: 5.6280\n",
      "Epoch 692/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 6.7500 - mse: 6.7500 - val_loss: 5.6262 - val_mse: 5.6262\n",
      "Epoch 693/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 6.7518 - mse: 6.7518 - val_loss: 5.6247 - val_mse: 5.6247\n",
      "Epoch 694/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 6.7463 - mse: 6.7463 - val_loss: 5.6201 - val_mse: 5.6201\n",
      "Epoch 695/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 6.7451 - mse: 6.7451 - val_loss: 5.6186 - val_mse: 5.6186\n",
      "Epoch 696/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 6.7462 - mse: 6.7462 - val_loss: 5.6220 - val_mse: 5.6220\n",
      "Epoch 697/1000\n",
      "128/128 [==============================] - 0s 381us/sample - loss: 6.7453 - mse: 6.7453 - val_loss: 5.6185 - val_mse: 5.6185\n",
      "Epoch 698/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 6.7371 - mse: 6.7371 - val_loss: 5.6120 - val_mse: 5.6120\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 299us/sample - loss: 6.7361 - mse: 6.7361 - val_loss: 5.6113 - val_mse: 5.6113\n",
      "Epoch 700/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 6.7314 - mse: 6.7314 - val_loss: 5.6011 - val_mse: 5.6011\n",
      "Epoch 701/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 6.7276 - mse: 6.7276 - val_loss: 5.6058 - val_mse: 5.6058\n",
      "Epoch 702/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 6.7265 - mse: 6.7265 - val_loss: 5.5996 - val_mse: 5.5996\n",
      "Epoch 703/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 6.7209 - mse: 6.7209 - val_loss: 5.5887 - val_mse: 5.5887\n",
      "Epoch 704/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 6.7205 - mse: 6.7205 - val_loss: 5.5806 - val_mse: 5.5806\n",
      "Epoch 705/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 6.7218 - mse: 6.7218 - val_loss: 5.5803 - val_mse: 5.5803\n",
      "Epoch 706/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 6.7125 - mse: 6.7125 - val_loss: 5.5833 - val_mse: 5.5833\n",
      "Epoch 707/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 6.7100 - mse: 6.7100 - val_loss: 5.5877 - val_mse: 5.5877\n",
      "Epoch 708/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 6.7099 - mse: 6.7099 - val_loss: 5.5826 - val_mse: 5.5826\n",
      "Epoch 709/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 6.7087 - mse: 6.7087 - val_loss: 5.5701 - val_mse: 5.5701\n",
      "Epoch 710/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 6.7008 - mse: 6.7008 - val_loss: 5.5742 - val_mse: 5.5742\n",
      "Epoch 711/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 6.7033 - mse: 6.7033 - val_loss: 5.5680 - val_mse: 5.5680\n",
      "Epoch 712/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 6.7017 - mse: 6.7017 - val_loss: 5.5706 - val_mse: 5.5706\n",
      "Epoch 713/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 6.6979 - mse: 6.6979 - val_loss: 5.5642 - val_mse: 5.5642\n",
      "Epoch 714/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 6.6947 - mse: 6.6947 - val_loss: 5.5603 - val_mse: 5.5603\n",
      "Epoch 715/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 6.6882 - mse: 6.6882 - val_loss: 5.5660 - val_mse: 5.5660\n",
      "Epoch 716/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 6.6831 - mse: 6.6831 - val_loss: 5.5602 - val_mse: 5.5602\n",
      "Epoch 717/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 6.6788 - mse: 6.6788 - val_loss: 5.5560 - val_mse: 5.5561\n",
      "Epoch 718/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 6.6826 - mse: 6.6826 - val_loss: 5.5670 - val_mse: 5.5670\n",
      "Epoch 719/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 6.6794 - mse: 6.6794 - val_loss: 5.5585 - val_mse: 5.5585\n",
      "Epoch 720/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 6.6742 - mse: 6.6742 - val_loss: 5.5557 - val_mse: 5.5557\n",
      "Epoch 721/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 6.6706 - mse: 6.6706 - val_loss: 5.5529 - val_mse: 5.5529\n",
      "Epoch 722/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 6.6690 - mse: 6.6690 - val_loss: 5.5443 - val_mse: 5.5443\n",
      "Epoch 723/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 6.6670 - mse: 6.6670 - val_loss: 5.5413 - val_mse: 5.5413\n",
      "Epoch 724/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 6.6582 - mse: 6.6582 - val_loss: 5.5395 - val_mse: 5.5395\n",
      "Epoch 725/1000\n",
      "128/128 [==============================] - 0s 270us/sample - loss: 6.6656 - mse: 6.6656 - val_loss: 5.5320 - val_mse: 5.5320\n",
      "Epoch 726/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 6.6579 - mse: 6.6579 - val_loss: 5.5291 - val_mse: 5.5291\n",
      "Epoch 727/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 6.6514 - mse: 6.6514 - val_loss: 5.5298 - val_mse: 5.5298\n",
      "Epoch 728/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 6.6572 - mse: 6.6572 - val_loss: 5.5254 - val_mse: 5.5254\n",
      "Epoch 729/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 6.6493 - mse: 6.6493 - val_loss: 5.5255 - val_mse: 5.5255\n",
      "Epoch 730/1000\n",
      "128/128 [==============================] - 0s 431us/sample - loss: 6.6522 - mse: 6.6522 - val_loss: 5.5235 - val_mse: 5.5235\n",
      "Epoch 731/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 6.6446 - mse: 6.6446 - val_loss: 5.5193 - val_mse: 5.5193\n",
      "Epoch 732/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 6.6420 - mse: 6.6420 - val_loss: 5.5212 - val_mse: 5.5212\n",
      "Epoch 733/1000\n",
      "128/128 [==============================] - 0s 435us/sample - loss: 6.6367 - mse: 6.6367 - val_loss: 5.5162 - val_mse: 5.5162\n",
      "Epoch 734/1000\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 6.6312 - mse: 6.6312 - val_loss: 5.5082 - val_mse: 5.5082\n",
      "Epoch 735/1000\n",
      "128/128 [==============================] - 0s 423us/sample - loss: 6.6298 - mse: 6.6298 - val_loss: 5.5030 - val_mse: 5.5030\n",
      "Epoch 736/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 6.6254 - mse: 6.6254 - val_loss: 5.5043 - val_mse: 5.5043\n",
      "Epoch 737/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 6.6206 - mse: 6.6206 - val_loss: 5.5076 - val_mse: 5.5076\n",
      "Epoch 738/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 6.6185 - mse: 6.6185 - val_loss: 5.5032 - val_mse: 5.5032\n",
      "Epoch 739/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 6.6254 - mse: 6.6254 - val_loss: 5.5027 - val_mse: 5.5027\n",
      "Epoch 740/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 6.6141 - mse: 6.6141 - val_loss: 5.5023 - val_mse: 5.5023\n",
      "Epoch 741/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 6.6216 - mse: 6.6216 - val_loss: 5.5034 - val_mse: 5.5034\n",
      "Epoch 742/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 6.6184 - mse: 6.6184 - val_loss: 5.4945 - val_mse: 5.4945\n",
      "Epoch 743/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 6.6065 - mse: 6.6065 - val_loss: 5.4969 - val_mse: 5.4969\n",
      "Epoch 744/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 6.6071 - mse: 6.6071 - val_loss: 5.4928 - val_mse: 5.4928\n",
      "Epoch 745/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 6.6044 - mse: 6.6044 - val_loss: 5.4833 - val_mse: 5.4833\n",
      "Epoch 746/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 6.6029 - mse: 6.6029 - val_loss: 5.4846 - val_mse: 5.4846\n",
      "Epoch 747/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 6.5949 - mse: 6.5949 - val_loss: 5.4728 - val_mse: 5.4728\n",
      "Epoch 748/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 6.5901 - mse: 6.5901 - val_loss: 5.4743 - val_mse: 5.4743\n",
      "Epoch 749/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 6.5898 - mse: 6.5898 - val_loss: 5.4756 - val_mse: 5.4756\n",
      "Epoch 750/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 6.5889 - mse: 6.5889 - val_loss: 5.4808 - val_mse: 5.4808\n",
      "Epoch 751/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 6.5911 - mse: 6.5911 - val_loss: 5.4719 - val_mse: 5.4719\n",
      "Epoch 752/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 6.5844 - mse: 6.5844 - val_loss: 5.4770 - val_mse: 5.4770\n",
      "Epoch 753/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 6.5813 - mse: 6.5813 - val_loss: 5.4737 - val_mse: 5.4737\n",
      "Epoch 754/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 6.5780 - mse: 6.5780 - val_loss: 5.4661 - val_mse: 5.4661\n",
      "Epoch 755/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 6.5725 - mse: 6.5725 - val_loss: 5.4531 - val_mse: 5.4531\n",
      "Epoch 756/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 6.5677 - mse: 6.5677 - val_loss: 5.4532 - val_mse: 5.4532\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 295us/sample - loss: 6.5644 - mse: 6.5644 - val_loss: 5.4513 - val_mse: 5.4513\n",
      "Epoch 758/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 6.5633 - mse: 6.5633 - val_loss: 5.4525 - val_mse: 5.4525\n",
      "Epoch 759/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 6.5612 - mse: 6.5612 - val_loss: 5.4522 - val_mse: 5.4522\n",
      "Epoch 760/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 6.5555 - mse: 6.5555 - val_loss: 5.4453 - val_mse: 5.4453\n",
      "Epoch 761/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 6.5555 - mse: 6.5555 - val_loss: 5.4493 - val_mse: 5.4493\n",
      "Epoch 762/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 6.5540 - mse: 6.5540 - val_loss: 5.4446 - val_mse: 5.4446\n",
      "Epoch 763/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 6.5529 - mse: 6.5529 - val_loss: 5.4425 - val_mse: 5.4425\n",
      "Epoch 764/1000\n",
      "128/128 [==============================] - 0s 269us/sample - loss: 6.5502 - mse: 6.5502 - val_loss: 5.4437 - val_mse: 5.4437\n",
      "Epoch 765/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 6.5485 - mse: 6.5485 - val_loss: 5.4377 - val_mse: 5.4377\n",
      "Epoch 766/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 6.5445 - mse: 6.5445 - val_loss: 5.4296 - val_mse: 5.4296\n",
      "Epoch 767/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 6.5426 - mse: 6.5426 - val_loss: 5.4264 - val_mse: 5.4264\n",
      "Epoch 768/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 6.5437 - mse: 6.5437 - val_loss: 5.4287 - val_mse: 5.4287\n",
      "Epoch 769/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.5402 - mse: 6.5402 - val_loss: 5.4244 - val_mse: 5.4244\n",
      "Epoch 770/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 6.5289 - mse: 6.5289 - val_loss: 5.4224 - val_mse: 5.4224\n",
      "Epoch 771/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 6.5253 - mse: 6.5253 - val_loss: 5.4218 - val_mse: 5.4218\n",
      "Epoch 772/1000\n",
      "128/128 [==============================] - 0s 264us/sample - loss: 6.5246 - mse: 6.5246 - val_loss: 5.4120 - val_mse: 5.4120\n",
      "Epoch 773/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.5170 - mse: 6.5170 - val_loss: 5.4104 - val_mse: 5.4104\n",
      "Epoch 774/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 6.5231 - mse: 6.5231 - val_loss: 5.4037 - val_mse: 5.4037\n",
      "Epoch 775/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 6.5212 - mse: 6.5212 - val_loss: 5.4059 - val_mse: 5.4059\n",
      "Epoch 776/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 6.5172 - mse: 6.5172 - val_loss: 5.4029 - val_mse: 5.4029\n",
      "Epoch 777/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 6.5073 - mse: 6.5073 - val_loss: 5.3984 - val_mse: 5.3984\n",
      "Epoch 778/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 6.5154 - mse: 6.5154 - val_loss: 5.3943 - val_mse: 5.3943\n",
      "Epoch 779/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.5075 - mse: 6.5075 - val_loss: 5.3998 - val_mse: 5.3998\n",
      "Epoch 780/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 6.5033 - mse: 6.5033 - val_loss: 5.3923 - val_mse: 5.3923\n",
      "Epoch 781/1000\n",
      "128/128 [==============================] - 0s 399us/sample - loss: 6.4947 - mse: 6.4947 - val_loss: 5.3893 - val_mse: 5.3893\n",
      "Epoch 782/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 6.5044 - mse: 6.5044 - val_loss: 5.3863 - val_mse: 5.3863\n",
      "Epoch 783/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 6.4975 - mse: 6.4975 - val_loss: 5.3796 - val_mse: 5.3796\n",
      "Epoch 784/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 6.4924 - mse: 6.4924 - val_loss: 5.3828 - val_mse: 5.3828\n",
      "Epoch 785/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 6.4868 - mse: 6.4868 - val_loss: 5.3869 - val_mse: 5.3869\n",
      "Epoch 786/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 6.4859 - mse: 6.4859 - val_loss: 5.3848 - val_mse: 5.3848\n",
      "Epoch 787/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 6.4787 - mse: 6.4787 - val_loss: 5.3767 - val_mse: 5.3767\n",
      "Epoch 788/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.4825 - mse: 6.4825 - val_loss: 5.3755 - val_mse: 5.3755\n",
      "Epoch 789/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 6.4787 - mse: 6.4787 - val_loss: 5.3737 - val_mse: 5.3737\n",
      "Epoch 790/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 6.4800 - mse: 6.4800 - val_loss: 5.3640 - val_mse: 5.3640\n",
      "Epoch 791/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 6.4722 - mse: 6.4722 - val_loss: 5.3555 - val_mse: 5.3555\n",
      "Epoch 792/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 6.4677 - mse: 6.4677 - val_loss: 5.3558 - val_mse: 5.3558\n",
      "Epoch 793/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 6.4689 - mse: 6.4689 - val_loss: 5.3551 - val_mse: 5.3551\n",
      "Epoch 794/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 6.4632 - mse: 6.4632 - val_loss: 5.3558 - val_mse: 5.3558\n",
      "Epoch 795/1000\n",
      "128/128 [==============================] - 0s 352us/sample - loss: 6.4585 - mse: 6.4585 - val_loss: 5.3630 - val_mse: 5.3630\n",
      "Epoch 796/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 6.4590 - mse: 6.4590 - val_loss: 5.3617 - val_mse: 5.3617\n",
      "Epoch 797/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.4553 - mse: 6.4553 - val_loss: 5.3618 - val_mse: 5.3618\n",
      "Epoch 798/1000\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 6.4491 - mse: 6.4491 - val_loss: 5.3585 - val_mse: 5.3585\n",
      "Epoch 799/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 6.4510 - mse: 6.4510 - val_loss: 5.3556 - val_mse: 5.3556\n",
      "Epoch 800/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 6.4494 - mse: 6.4494 - val_loss: 5.3511 - val_mse: 5.3511\n",
      "Epoch 801/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 6.4442 - mse: 6.4442 - val_loss: 5.3447 - val_mse: 5.3447\n",
      "Epoch 802/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 6.4397 - mse: 6.4397 - val_loss: 5.3438 - val_mse: 5.3438\n",
      "Epoch 803/1000\n",
      "128/128 [==============================] - 0s 259us/sample - loss: 6.4367 - mse: 6.4367 - val_loss: 5.3419 - val_mse: 5.3419\n",
      "Epoch 804/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 6.4327 - mse: 6.4327 - val_loss: 5.3395 - val_mse: 5.3395\n",
      "Epoch 805/1000\n",
      "128/128 [==============================] - 0s 248us/sample - loss: 6.4319 - mse: 6.4319 - val_loss: 5.3432 - val_mse: 5.3432\n",
      "Epoch 806/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 6.4304 - mse: 6.4304 - val_loss: 5.3363 - val_mse: 5.3363\n",
      "Epoch 807/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 6.4302 - mse: 6.4302 - val_loss: 5.3342 - val_mse: 5.3342\n",
      "Epoch 808/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 6.4259 - mse: 6.4259 - val_loss: 5.3263 - val_mse: 5.3263\n",
      "Epoch 809/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 6.4187 - mse: 6.4187 - val_loss: 5.3264 - val_mse: 5.3264\n",
      "Epoch 810/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 6.4147 - mse: 6.4147 - val_loss: 5.3249 - val_mse: 5.3249\n",
      "Epoch 811/1000\n",
      "128/128 [==============================] - 0s 256us/sample - loss: 6.4162 - mse: 6.4162 - val_loss: 5.3198 - val_mse: 5.3198\n",
      "Epoch 812/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 6.4112 - mse: 6.4112 - val_loss: 5.3148 - val_mse: 5.3148\n",
      "Epoch 813/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 6.4201 - mse: 6.4201 - val_loss: 5.3150 - val_mse: 5.3150\n",
      "Epoch 814/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 6.4075 - mse: 6.4075 - val_loss: 5.3179 - val_mse: 5.3179\n",
      "Epoch 815/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 362us/sample - loss: 6.4082 - mse: 6.4082 - val_loss: 5.3167 - val_mse: 5.3167\n",
      "Epoch 816/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 6.4055 - mse: 6.4055 - val_loss: 5.3126 - val_mse: 5.3126\n",
      "Epoch 817/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 6.3962 - mse: 6.3962 - val_loss: 5.3103 - val_mse: 5.3103\n",
      "Epoch 818/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 6.3945 - mse: 6.3945 - val_loss: 5.3004 - val_mse: 5.3004\n",
      "Epoch 819/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 6.3907 - mse: 6.3907 - val_loss: 5.3018 - val_mse: 5.3018\n",
      "Epoch 820/1000\n",
      "128/128 [==============================] - 0s 270us/sample - loss: 6.3938 - mse: 6.3938 - val_loss: 5.2965 - val_mse: 5.2965\n",
      "Epoch 821/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 6.3866 - mse: 6.3866 - val_loss: 5.2951 - val_mse: 5.2951\n",
      "Epoch 822/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 6.3867 - mse: 6.3867 - val_loss: 5.2885 - val_mse: 5.2885\n",
      "Epoch 823/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.3851 - mse: 6.3851 - val_loss: 5.2916 - val_mse: 5.2916\n",
      "Epoch 824/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 6.3905 - mse: 6.3905 - val_loss: 5.2866 - val_mse: 5.2866\n",
      "Epoch 825/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 6.3886 - mse: 6.3886 - val_loss: 5.2920 - val_mse: 5.2920\n",
      "Epoch 826/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 6.3734 - mse: 6.3734 - val_loss: 5.2809 - val_mse: 5.2809\n",
      "Epoch 827/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 6.3783 - mse: 6.3783 - val_loss: 5.2785 - val_mse: 5.2785\n",
      "Epoch 828/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 6.3708 - mse: 6.3708 - val_loss: 5.2767 - val_mse: 5.2767\n",
      "Epoch 829/1000\n",
      "128/128 [==============================] - 0s 251us/sample - loss: 6.3704 - mse: 6.3704 - val_loss: 5.2721 - val_mse: 5.2721\n",
      "Epoch 830/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 6.3637 - mse: 6.3637 - val_loss: 5.2717 - val_mse: 5.2717\n",
      "Epoch 831/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 6.3590 - mse: 6.3590 - val_loss: 5.2663 - val_mse: 5.2663\n",
      "Epoch 832/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 6.3582 - mse: 6.3582 - val_loss: 5.2658 - val_mse: 5.2658\n",
      "Epoch 833/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 6.3546 - mse: 6.3546 - val_loss: 5.2572 - val_mse: 5.2572\n",
      "Epoch 834/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 6.3531 - mse: 6.3531 - val_loss: 5.2508 - val_mse: 5.2508\n",
      "Epoch 835/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 6.3518 - mse: 6.3518 - val_loss: 5.2517 - val_mse: 5.2517\n",
      "Epoch 836/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 6.3487 - mse: 6.3487 - val_loss: 5.2520 - val_mse: 5.2520\n",
      "Epoch 837/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 6.3454 - mse: 6.3454 - val_loss: 5.2517 - val_mse: 5.2517\n",
      "Epoch 838/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 6.3450 - mse: 6.3450 - val_loss: 5.2502 - val_mse: 5.2502\n",
      "Epoch 839/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 6.3438 - mse: 6.3438 - val_loss: 5.2412 - val_mse: 5.2412\n",
      "Epoch 840/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 6.3321 - mse: 6.3321 - val_loss: 5.2407 - val_mse: 5.2407\n",
      "Epoch 841/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 6.3420 - mse: 6.3420 - val_loss: 5.2468 - val_mse: 5.2468\n",
      "Epoch 842/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 6.3307 - mse: 6.3307 - val_loss: 5.2465 - val_mse: 5.2465\n",
      "Epoch 843/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 6.3297 - mse: 6.3297 - val_loss: 5.2512 - val_mse: 5.2512\n",
      "Epoch 844/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 6.3245 - mse: 6.3245 - val_loss: 5.2475 - val_mse: 5.2475\n",
      "Epoch 845/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 6.3241 - mse: 6.3241 - val_loss: 5.2526 - val_mse: 5.2526\n",
      "Epoch 846/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 6.3167 - mse: 6.3167 - val_loss: 5.2392 - val_mse: 5.2392\n",
      "Epoch 847/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 6.3187 - mse: 6.3187 - val_loss: 5.2336 - val_mse: 5.2336\n",
      "Epoch 848/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.3162 - mse: 6.3162 - val_loss: 5.2330 - val_mse: 5.2330\n",
      "Epoch 849/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 6.3166 - mse: 6.3166 - val_loss: 5.2312 - val_mse: 5.2312\n",
      "Epoch 850/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 6.3099 - mse: 6.3099 - val_loss: 5.2192 - val_mse: 5.2192\n",
      "Epoch 851/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 6.3070 - mse: 6.3070 - val_loss: 5.2237 - val_mse: 5.2237\n",
      "Epoch 852/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 6.3038 - mse: 6.3038 - val_loss: 5.2247 - val_mse: 5.2247\n",
      "Epoch 853/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.3026 - mse: 6.3026 - val_loss: 5.2192 - val_mse: 5.2192\n",
      "Epoch 854/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 6.2982 - mse: 6.2982 - val_loss: 5.2174 - val_mse: 5.2174\n",
      "Epoch 855/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.2977 - mse: 6.2977 - val_loss: 5.2076 - val_mse: 5.2076\n",
      "Epoch 856/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 6.3013 - mse: 6.3013 - val_loss: 5.1984 - val_mse: 5.1984\n",
      "Epoch 857/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 6.2909 - mse: 6.2909 - val_loss: 5.2051 - val_mse: 5.2051\n",
      "Epoch 858/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 6.2885 - mse: 6.2886 - val_loss: 5.1936 - val_mse: 5.1936\n",
      "Epoch 859/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 6.2872 - mse: 6.2872 - val_loss: 5.1864 - val_mse: 5.1864\n",
      "Epoch 860/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 6.2837 - mse: 6.2837 - val_loss: 5.1811 - val_mse: 5.1811\n",
      "Epoch 861/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 6.2817 - mse: 6.2817 - val_loss: 5.1766 - val_mse: 5.1766\n",
      "Epoch 862/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 6.2758 - mse: 6.2758 - val_loss: 5.1829 - val_mse: 5.1829\n",
      "Epoch 863/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 6.2740 - mse: 6.2740 - val_loss: 5.1836 - val_mse: 5.1836\n",
      "Epoch 864/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 6.2760 - mse: 6.2760 - val_loss: 5.1880 - val_mse: 5.1880\n",
      "Epoch 865/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 6.2714 - mse: 6.2714 - val_loss: 5.1922 - val_mse: 5.1922\n",
      "Epoch 866/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 6.2666 - mse: 6.2666 - val_loss: 5.1860 - val_mse: 5.1860\n",
      "Epoch 867/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 6.2626 - mse: 6.2626 - val_loss: 5.1862 - val_mse: 5.1862\n",
      "Epoch 868/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 6.2605 - mse: 6.2605 - val_loss: 5.1869 - val_mse: 5.1869\n",
      "Epoch 869/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 6.2597 - mse: 6.2597 - val_loss: 5.1753 - val_mse: 5.1753\n",
      "Epoch 870/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 6.2587 - mse: 6.2587 - val_loss: 5.1839 - val_mse: 5.1839\n",
      "Epoch 871/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 6.2525 - mse: 6.2525 - val_loss: 5.1757 - val_mse: 5.1757\n",
      "Epoch 872/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 6.2489 - mse: 6.2489 - val_loss: 5.1784 - val_mse: 5.1784\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 280us/sample - loss: 6.2475 - mse: 6.2475 - val_loss: 5.1716 - val_mse: 5.1716\n",
      "Epoch 874/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 6.2434 - mse: 6.2434 - val_loss: 5.1691 - val_mse: 5.1691\n",
      "Epoch 875/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 6.2420 - mse: 6.2420 - val_loss: 5.1711 - val_mse: 5.1711\n",
      "Epoch 876/1000\n",
      "128/128 [==============================] - 0s 443us/sample - loss: 6.2390 - mse: 6.2390 - val_loss: 5.1643 - val_mse: 5.1643\n",
      "Epoch 877/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.2411 - mse: 6.2411 - val_loss: 5.1613 - val_mse: 5.1613\n",
      "Epoch 878/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 6.2367 - mse: 6.2367 - val_loss: 5.1661 - val_mse: 5.1661\n",
      "Epoch 879/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 6.2317 - mse: 6.2317 - val_loss: 5.1593 - val_mse: 5.1593\n",
      "Epoch 880/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.2283 - mse: 6.2283 - val_loss: 5.1591 - val_mse: 5.1591\n",
      "Epoch 881/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 6.2262 - mse: 6.2262 - val_loss: 5.1534 - val_mse: 5.1534\n",
      "Epoch 882/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 6.2271 - mse: 6.2271 - val_loss: 5.1447 - val_mse: 5.1447\n",
      "Epoch 883/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 6.2255 - mse: 6.2255 - val_loss: 5.1417 - val_mse: 5.1417\n",
      "Epoch 884/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 6.2245 - mse: 6.2245 - val_loss: 5.1376 - val_mse: 5.1376\n",
      "Epoch 885/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 6.2263 - mse: 6.2263 - val_loss: 5.1409 - val_mse: 5.1409\n",
      "Epoch 886/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 6.2198 - mse: 6.2198 - val_loss: 5.1341 - val_mse: 5.1341\n",
      "Epoch 887/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 6.2100 - mse: 6.2100 - val_loss: 5.1257 - val_mse: 5.1257\n",
      "Epoch 888/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 6.2123 - mse: 6.2123 - val_loss: 5.1267 - val_mse: 5.1267\n",
      "Epoch 889/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 6.2076 - mse: 6.2076 - val_loss: 5.1315 - val_mse: 5.1315\n",
      "Epoch 890/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 6.1981 - mse: 6.1981 - val_loss: 5.1293 - val_mse: 5.1293\n",
      "Epoch 891/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 6.2035 - mse: 6.2035 - val_loss: 5.1247 - val_mse: 5.1247\n",
      "Epoch 892/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 6.1984 - mse: 6.1984 - val_loss: 5.1204 - val_mse: 5.1204\n",
      "Epoch 893/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 6.1971 - mse: 6.1971 - val_loss: 5.1230 - val_mse: 5.1230\n",
      "Epoch 894/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 6.1912 - mse: 6.1912 - val_loss: 5.1198 - val_mse: 5.1198\n",
      "Epoch 895/1000\n",
      "128/128 [==============================] - 0s 264us/sample - loss: 6.1908 - mse: 6.1908 - val_loss: 5.1226 - val_mse: 5.1226\n",
      "Epoch 896/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 6.1883 - mse: 6.1883 - val_loss: 5.1208 - val_mse: 5.1208\n",
      "Epoch 897/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 6.1843 - mse: 6.1843 - val_loss: 5.1126 - val_mse: 5.1126\n",
      "Epoch 898/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 6.1791 - mse: 6.1791 - val_loss: 5.1061 - val_mse: 5.1061\n",
      "Epoch 899/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 6.1815 - mse: 6.1815 - val_loss: 5.1034 - val_mse: 5.1034\n",
      "Epoch 900/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 6.1815 - mse: 6.1815 - val_loss: 5.0977 - val_mse: 5.0977\n",
      "Epoch 901/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 6.1743 - mse: 6.1743 - val_loss: 5.1088 - val_mse: 5.1088\n",
      "Epoch 902/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 6.1707 - mse: 6.1707 - val_loss: 5.1059 - val_mse: 5.1059\n",
      "Epoch 903/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 6.1659 - mse: 6.1659 - val_loss: 5.0983 - val_mse: 5.0983\n",
      "Epoch 904/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 6.1697 - mse: 6.1697 - val_loss: 5.1037 - val_mse: 5.1037\n",
      "Epoch 905/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 6.1612 - mse: 6.1612 - val_loss: 5.0977 - val_mse: 5.0977\n",
      "Epoch 906/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 6.1636 - mse: 6.1636 - val_loss: 5.0907 - val_mse: 5.0907\n",
      "Epoch 907/1000\n",
      "128/128 [==============================] - 0s 264us/sample - loss: 6.1564 - mse: 6.1564 - val_loss: 5.0842 - val_mse: 5.0842\n",
      "Epoch 908/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.1512 - mse: 6.1512 - val_loss: 5.0804 - val_mse: 5.0804\n",
      "Epoch 909/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 6.1522 - mse: 6.1522 - val_loss: 5.0797 - val_mse: 5.0797\n",
      "Epoch 910/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 6.1470 - mse: 6.1470 - val_loss: 5.0814 - val_mse: 5.0814\n",
      "Epoch 911/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 6.1469 - mse: 6.1469 - val_loss: 5.0839 - val_mse: 5.0839\n",
      "Epoch 912/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 6.1475 - mse: 6.1475 - val_loss: 5.0742 - val_mse: 5.0742\n",
      "Epoch 913/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 6.1444 - mse: 6.1444 - val_loss: 5.0684 - val_mse: 5.0684\n",
      "Epoch 914/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 6.1395 - mse: 6.1395 - val_loss: 5.0725 - val_mse: 5.0725\n",
      "Epoch 915/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 6.1379 - mse: 6.1379 - val_loss: 5.0666 - val_mse: 5.0666\n",
      "Epoch 916/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 6.1346 - mse: 6.1346 - val_loss: 5.0574 - val_mse: 5.0574\n",
      "Epoch 917/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 6.1289 - mse: 6.1289 - val_loss: 5.0507 - val_mse: 5.0507\n",
      "Epoch 918/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 6.1286 - mse: 6.1286 - val_loss: 5.0478 - val_mse: 5.0478\n",
      "Epoch 919/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 6.1234 - mse: 6.1234 - val_loss: 5.0497 - val_mse: 5.0497\n",
      "Epoch 920/1000\n",
      "128/128 [==============================] - 0s 261us/sample - loss: 6.1225 - mse: 6.1225 - val_loss: 5.0554 - val_mse: 5.0554\n",
      "Epoch 921/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 6.1209 - mse: 6.1209 - val_loss: 5.0467 - val_mse: 5.0467\n",
      "Epoch 922/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 6.1156 - mse: 6.1156 - val_loss: 5.0495 - val_mse: 5.0495\n",
      "Epoch 923/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 6.1184 - mse: 6.1184 - val_loss: 5.0508 - val_mse: 5.0508\n",
      "Epoch 924/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 6.1167 - mse: 6.1167 - val_loss: 5.0397 - val_mse: 5.0397\n",
      "Epoch 925/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 6.1141 - mse: 6.1141 - val_loss: 5.0503 - val_mse: 5.0503\n",
      "Epoch 926/1000\n",
      "128/128 [==============================] - 0s 260us/sample - loss: 6.1120 - mse: 6.1120 - val_loss: 5.0519 - val_mse: 5.0519\n",
      "Epoch 927/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 6.1059 - mse: 6.1059 - val_loss: 5.0518 - val_mse: 5.0518\n",
      "Epoch 928/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 6.1037 - mse: 6.1037 - val_loss: 5.0492 - val_mse: 5.0492\n",
      "Epoch 929/1000\n",
      "128/128 [==============================] - 0s 258us/sample - loss: 6.1081 - mse: 6.1081 - val_loss: 5.0424 - val_mse: 5.0424\n",
      "Epoch 930/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 6.0960 - mse: 6.0960 - val_loss: 5.0350 - val_mse: 5.0350\n",
      "Epoch 931/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 298us/sample - loss: 6.0976 - mse: 6.0976 - val_loss: 5.0314 - val_mse: 5.0314\n",
      "Epoch 932/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 6.0934 - mse: 6.0934 - val_loss: 5.0270 - val_mse: 5.0270\n",
      "Epoch 933/1000\n",
      "128/128 [==============================] - 0s 247us/sample - loss: 6.0909 - mse: 6.0908 - val_loss: 5.0313 - val_mse: 5.0313\n",
      "Epoch 934/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 6.0877 - mse: 6.0877 - val_loss: 5.0299 - val_mse: 5.0299\n",
      "Epoch 935/1000\n",
      "128/128 [==============================] - 0s 265us/sample - loss: 6.0873 - mse: 6.0873 - val_loss: 5.0220 - val_mse: 5.0220\n",
      "Epoch 936/1000\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 6.0810 - mse: 6.0810 - val_loss: 5.0188 - val_mse: 5.0188\n",
      "Epoch 937/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 6.0814 - mse: 6.0814 - val_loss: 5.0181 - val_mse: 5.0181\n",
      "Epoch 938/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 6.0750 - mse: 6.0750 - val_loss: 5.0229 - val_mse: 5.0229\n",
      "Epoch 939/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 6.0701 - mse: 6.0701 - val_loss: 5.0160 - val_mse: 5.0160\n",
      "Epoch 940/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 6.0741 - mse: 6.0741 - val_loss: 5.0186 - val_mse: 5.0186\n",
      "Epoch 941/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 6.0751 - mse: 6.0751 - val_loss: 5.0176 - val_mse: 5.0176\n",
      "Epoch 942/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 6.0665 - mse: 6.0665 - val_loss: 5.0119 - val_mse: 5.0119\n",
      "Epoch 943/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 6.0669 - mse: 6.0669 - val_loss: 5.0109 - val_mse: 5.0109\n",
      "Epoch 944/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 6.0641 - mse: 6.0641 - val_loss: 5.0102 - val_mse: 5.0102\n",
      "Epoch 945/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 6.0646 - mse: 6.0646 - val_loss: 5.0154 - val_mse: 5.0154\n",
      "Epoch 946/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 6.0575 - mse: 6.0575 - val_loss: 5.0132 - val_mse: 5.0132\n",
      "Epoch 947/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 6.0524 - mse: 6.0524 - val_loss: 5.0052 - val_mse: 5.0052\n",
      "Epoch 948/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 6.0521 - mse: 6.0521 - val_loss: 4.9997 - val_mse: 4.9997\n",
      "Epoch 949/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 6.0456 - mse: 6.0456 - val_loss: 4.9921 - val_mse: 4.9921\n",
      "Epoch 950/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 6.0506 - mse: 6.0506 - val_loss: 4.9911 - val_mse: 4.9911\n",
      "Epoch 951/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 6.0403 - mse: 6.0403 - val_loss: 4.9825 - val_mse: 4.9825\n",
      "Epoch 952/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 6.0424 - mse: 6.0424 - val_loss: 4.9749 - val_mse: 4.9749\n",
      "Epoch 953/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 6.0354 - mse: 6.0354 - val_loss: 4.9833 - val_mse: 4.9833\n",
      "Epoch 954/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 6.0410 - mse: 6.0410 - val_loss: 4.9818 - val_mse: 4.9818\n",
      "Epoch 955/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 6.0307 - mse: 6.0307 - val_loss: 4.9735 - val_mse: 4.9735\n",
      "Epoch 956/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 6.0322 - mse: 6.0322 - val_loss: 4.9765 - val_mse: 4.9765\n",
      "Epoch 957/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 6.0248 - mse: 6.0248 - val_loss: 4.9722 - val_mse: 4.9722\n",
      "Epoch 958/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 6.0288 - mse: 6.0288 - val_loss: 4.9687 - val_mse: 4.9687\n",
      "Epoch 959/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 6.0200 - mse: 6.0200 - val_loss: 4.9624 - val_mse: 4.9624\n",
      "Epoch 960/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 6.0195 - mse: 6.0195 - val_loss: 4.9646 - val_mse: 4.9646\n",
      "Epoch 961/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 6.0183 - mse: 6.0183 - val_loss: 4.9577 - val_mse: 4.9577\n",
      "Epoch 962/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 6.0209 - mse: 6.0209 - val_loss: 4.9489 - val_mse: 4.9489\n",
      "Epoch 963/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 6.0114 - mse: 6.0114 - val_loss: 4.9484 - val_mse: 4.9484\n",
      "Epoch 964/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 6.0077 - mse: 6.0077 - val_loss: 4.9502 - val_mse: 4.9502\n",
      "Epoch 965/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 6.0084 - mse: 6.0084 - val_loss: 4.9471 - val_mse: 4.9471\n",
      "Epoch 966/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 6.0005 - mse: 6.0005 - val_loss: 4.9468 - val_mse: 4.9468\n",
      "Epoch 967/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 6.0027 - mse: 6.0027 - val_loss: 4.9413 - val_mse: 4.9413\n",
      "Epoch 968/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 6.0013 - mse: 6.0013 - val_loss: 4.9433 - val_mse: 4.9433\n",
      "Epoch 969/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 5.9943 - mse: 5.9943 - val_loss: 4.9494 - val_mse: 4.9494\n",
      "Epoch 970/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 5.9903 - mse: 5.9903 - val_loss: 4.9491 - val_mse: 4.9491\n",
      "Epoch 971/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 5.9896 - mse: 5.9896 - val_loss: 4.9383 - val_mse: 4.9383\n",
      "Epoch 972/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 5.9893 - mse: 5.9893 - val_loss: 4.9344 - val_mse: 4.9344\n",
      "Epoch 973/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 5.9896 - mse: 5.9896 - val_loss: 4.9405 - val_mse: 4.9405\n",
      "Epoch 974/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 5.9821 - mse: 5.9821 - val_loss: 4.9435 - val_mse: 4.9435\n",
      "Epoch 975/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 5.9764 - mse: 5.9764 - val_loss: 4.9402 - val_mse: 4.9402\n",
      "Epoch 976/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 5.9814 - mse: 5.9814 - val_loss: 4.9349 - val_mse: 4.9349\n",
      "Epoch 977/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 5.9750 - mse: 5.9750 - val_loss: 4.9311 - val_mse: 4.9311\n",
      "Epoch 978/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 5.9706 - mse: 5.9706 - val_loss: 4.9221 - val_mse: 4.9221\n",
      "Epoch 979/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 5.9740 - mse: 5.9740 - val_loss: 4.9174 - val_mse: 4.9174\n",
      "Epoch 980/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 5.9741 - mse: 5.9741 - val_loss: 4.9203 - val_mse: 4.9203\n",
      "Epoch 981/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 5.9665 - mse: 5.9665 - val_loss: 4.9200 - val_mse: 4.9200\n",
      "Epoch 982/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 5.9626 - mse: 5.9626 - val_loss: 4.9175 - val_mse: 4.9175\n",
      "Epoch 983/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 5.9662 - mse: 5.9662 - val_loss: 4.9219 - val_mse: 4.9219\n",
      "Epoch 984/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 5.9589 - mse: 5.9589 - val_loss: 4.9187 - val_mse: 4.9187\n",
      "Epoch 985/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 5.9590 - mse: 5.9590 - val_loss: 4.9111 - val_mse: 4.9111\n",
      "Epoch 986/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 5.9498 - mse: 5.9498 - val_loss: 4.9112 - val_mse: 4.9112\n",
      "Epoch 987/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 5.9507 - mse: 5.9507 - val_loss: 4.9119 - val_mse: 4.9119\n",
      "Epoch 988/1000\n",
      "128/128 [==============================] - 0s 275us/sample - loss: 5.9465 - mse: 5.9465 - val_loss: 4.9072 - val_mse: 4.9072\n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 284us/sample - loss: 5.9497 - mse: 5.9497 - val_loss: 4.9044 - val_mse: 4.9044\n",
      "Epoch 990/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 5.9481 - mse: 5.9481 - val_loss: 4.9020 - val_mse: 4.9020\n",
      "Epoch 991/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 5.9468 - mse: 5.9468 - val_loss: 4.8960 - val_mse: 4.8960\n",
      "Epoch 992/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 5.9397 - mse: 5.9397 - val_loss: 4.8919 - val_mse: 4.8919\n",
      "Epoch 993/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 5.9319 - mse: 5.9319 - val_loss: 4.8874 - val_mse: 4.8874\n",
      "Epoch 994/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 5.9299 - mse: 5.9299 - val_loss: 4.8813 - val_mse: 4.8813\n",
      "Epoch 995/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 5.9284 - mse: 5.9284 - val_loss: 4.8844 - val_mse: 4.8844\n",
      "Epoch 996/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 5.9266 - mse: 5.9266 - val_loss: 4.8856 - val_mse: 4.8856\n",
      "Epoch 997/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 5.9210 - mse: 5.9210 - val_loss: 4.8842 - val_mse: 4.8842\n",
      "Epoch 998/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 5.9268 - mse: 5.9268 - val_loss: 4.8838 - val_mse: 4.8838\n",
      "Epoch 999/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 5.9192 - mse: 5.9192 - val_loss: 4.8882 - val_mse: 4.8882\n",
      "Epoch 1000/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 5.9184 - mse: 5.9184 - val_loss: 4.8816 - val_mse: 4.8816\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Lets first remove previous logs\n",
    "!rm -rf ./logs/ \n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = NN_model.fit(train_Xdf.values, train_Ydf.values,\n",
    "                    batch_size=10,\n",
    "                    epochs=1000, # Number of times we iterate over all the dataset\n",
    "                    #validation_data=(validate_Xdf, validate_Ydf),\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks=[tensorboard_callback]) # to latter see how the training went\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the MSE decresed during the training. For this we'll use tensorboard, note you should have it installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7901), started 0:15:32 ago. (Use '!kill 7901' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f37272004228006c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f37272004228006c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check how the NN predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>throw-trash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.619633</td>\n",
       "      <td>-3.351252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.820040</td>\n",
       "      <td>-1.053583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.647676</td>\n",
       "      <td>1.294183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.025087</td>\n",
       "      <td>1.388216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.863550</td>\n",
       "      <td>3.042969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correct  throw-trash\n",
       "0 -0.619633    -3.351252\n",
       "1 -3.820040    -1.053583\n",
       "2 -4.647676     1.294183\n",
       "3  3.025087     1.388216\n",
       "4  1.863550     3.042969"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = pd.DataFrame(NN_model.predict(test_Xdf),\n",
    "                                columns=['correct', 'throw-trash'])\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep output between [0,1]\n",
    "\n",
    "So clearly there is a problem here, right?\n",
    "\n",
    "We'd like our output to be between $[0,1]$. And in our case we can go for a work around, the **sigmoid** function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZwV1Zn/8c/TCw10swgtzb4oiDuiLW5xBJcIjkJcJtEkJjpxTDJDlkkyiZkkJqPJZJ35JTOaxcliVolJNKIhYoh2FqMCIqCACLI3O8jS3UAv9/n9cQu83bcamu6uW3f5vl+v++q6p05VPV33dj1dp6rOMXdHREQKV1HcAYiISLyUCERECpwSgYhIgVMiEBEpcEoEIiIFTolARKTAKRFIRpnZF8zsZxFv41IzWxnlNjqzXTN70My+eJT5XzSznWa2NZoI293ud83sc5ncpmSXkrgDkPxiZnUpb3sDh4CW4P37MxGDu/8FGJ+JbXXXds1sJPBxYJS7b+/WwFpv5zbgDnd/y+Eyd/9AVNuT3KAzAulW7l5x+AVsAK5LKft53PFlsZHAriiTgEh7lAgkDj3M7Cdmtt/MlplZ9eEZZjbUzH5jZjvMbK2Zfbi9lZjZNWa2PFhPrZl9IiifbGabUuqda2YvBfV+ZWa/PNxEc7iumX3SzLab2RYze1uw7tfMbLeZ/XvKusrM7Jtmtjl4fdPMytrZ7kQzWxRs95dAz3Z+jyuBPwBDzawuaEJqta6g3rqg7uEmtoePsh9HmNkjwX7cZWb3mdlpwHeBi4Lt7AnqtmqyMrN/MrPVwe8+28yGpsxzM/uAma0ysz1mdr+ZWXufkeQGJQKJw3RgFtAfmA3cB2BmRcDjwBJgGHAF8FEzu7qd9fwAeL+79wHOBJ5uW8HMegCPAg8CA4CHgOvbVBtM8iA9DLgb+D/g3cB5wKXA58xsTFD3M8CFwDnABGAS8Nl2tvtb4KfBdn8F3Bj2S7j7PGAasDk4c7qtnd+3rfb2YzHwBLAeGB38XrPcfQXwAeC5YDv9Q+K+HPgy8HZgSLCOWW2qXQucD5wd1Gvv85EcoUQgcfiru89x9xaSB8oJQfn5wInufo+7N7r7GpIH5ZvbWU8TcLqZ9XX3N9x9UUidC0leC/sfd29y90eA+SHr+ZK7N5E86FUC33L3/e6+DFieEuO7gHvcfbu77wD+A7i1ne2WAt8MtvtrYMEx9svxam8/TgKGAv/m7vXuftDd/9rBdb4L+KG7L3L3Q8CnSZ5BjE6p8xV33+PuG4BnSCZFyWFKBBKH1LtiGoCeZlYCjCLZPLLn8Av4d6CqnfXcCFwDrDezP5nZRSF1hgK13rp3xY1t6uwKDqYAB4Kf21LmHwAqUta3PmXe+qCsI9tdH1KvK9rbjyOA9e7e3Il1tvr93L0O2EXyrKK97VYgOU2JQLLJRmCtu/dPefVx92vCKrv7AnefAQwi2QzzcEi1LcCwNu3YI7oQ42aSCeuwkUFZR7Y78ji2U0/yrivgSHPPiR1cdiMwMkgKbR2ru+FWv5+ZlQMDgdoObltykBKBZJP5wH4z+5SZ9TKzYjM708zOb1vRzHqY2bvMrF/QpLMPSISs8zmSt6/ONLMSM5tBsumksx4CPmtmJ5pZJclrCmHPRTwHNAMfNrNSM7vhOLf7Gsn/8P/ezEpJXoco6+Cy80kmoq+YWbmZ9TSzS4J524DhwTWMMA8Bt5vZOcFF8P8EXnD3dccRu+QYJQLJGkHzzLUk25zXAjuB7wP92lnkVmCdme0jeRH0XSHrbARuAN4H7CF5EfgJks83dMYXgYXAUuBlYFFQ1t52bwN2A+8AHunoRtx9L/DPJH//WpJnCJuOutCby7YA1wFjSd7CuynYPiQvqC8DtprZzpBl5wGfA35DMpmcTPvXaCRPmAamkUJjZi8A33X3H8Udi0g20BmB5D0zu8zMBgdNQ+8ledvjk3HHJZIt1MWEFILxJC8klwNrgJvcfUu8IYlkDzUNiYgUODUNiYgUuJxrGqqsrPTRo0d3atn6+nrKy8u7N6BupPi6RvF1XbbHqPg678UXX9zp7uHPorh7Tr3OO+8876xnnnmm08tmguLrGsXXddkeo+LrPGCht3NcVdOQiEiBUyIQESlwSgQiIgVOiUBEpMApEYiIFLjIbh81sx+S7EBsu7ufGTLfgG+R7E++AbjNwwcWERHJqETCaUokaG5xmluS0y0JJ+FOwpPz3cEJ3gd339TuT/Dq1n34kTKOLOPuOJB8hjf5IG9yHbw5HTzg+2a95DYOFx6ue+7IE+jVo7jbft8onyN4kOTQeT9pZ/40YFzwugD4TvBTRCRUS8LZ29BEXWMz9YeaqTvUTN3BlOlDh6dbqDvURP2hliNl9YeaaWxxmlsSNCecppbgQJ9I0BSUNyWSPxNd6XDh2b902+/bnj9+/DJOPrH7xgOKLBG4+5/bDG/X1gzgJ8H9rc+bWX8zG+LqA0akYDW3JKjdc4B1uxrYsKuedbsaWB/83LznAA2NLfDUU3GHmXfifLJ4GK2HDNwUlKUlAjO7E7gToKqqipqamk5tsK6urtPLZoLi6xrF13WZiLGxxdl5wNnWkGB7g7O9IcG24OeuA06Luj87phdemM/Giu67xJsTXUy4+wPAAwDV1dU+efLkTq2npqaGzi6bCYqvaxRf10UR47qd9fx2cS3z1+5m3c56tuw7eKT9Wzpn0qTzGTuoT7etL85EUEvrsWOHo3FRRfLCG/WNPLF0M4+8VMtLG/bEHU6nlBQZJcVGaVERJcVGSXERxWYUGZgZZlAUvC8K3h9oaKCiojx433qekVwOOPKeoOzNaTjyrlWdw0XJdfUs7b4LxRBvIphNchzZWSQvEu/V9QGR3HWouYWnV2znkZdqqVm5naaI2ngqykooLyumvKyEPmUllAevw9MVPUuSdXoUU9GzlIqgbnlZCT2KiygtLmpzgH9zurS4iJIio7jIjhy0j0fyjOqyCH7raEV5++hDwGSg0sw2AZ8HSgHc/bvAHJK3jq4mefvo7VHFIiLRcHcWrn+DRxbV8rulm9l3sLnL6xxY3oNRA3szamA5owb2ZvTAckYO7M2oAb1ZsuBvXD5lSjdELqmivGvolmPMd+Bfotq+iERn7c56Hl20iUcX17Jx94HjXn5Iv56MHJA8yI+q7M2oAeXBwb83fXqWtrtcUSf+S5djy4mLxSISv92H2/0X1bJ44/G1+586uA/XTxzG5PGDGDWwd7e3cUvXKBGIyFHtqjvEl363gtlLNtN8HE9aDepTxoxzhnL9xOGcPrRvhBFKVykRiEi71u2s570/ms/6XQ0dqt+rtJipZw7m+onDuGRsJcVFasrJBUoEIhLqpQ1v8L4fL2R3feNR6xUZXDK2kusnDuPqMwZTXqbDSq7RJyYiaeYt38bMhxZxsCnRbp1TB/fhhnOHMeOcYVT17ZnB6KS7KRGISCs/f2E9n/vtK6Edr/XpWcItk0Zy/cRhnDZE7f75QolARIDkMwG/ea2Rx9e8Ejp/WP9e/PgfJzF2UPf1einZQYlARGhqSXDXb17m8TVNofPPGNqXH912PoPUBJSXlAhEClzdoWY++LMX+cuqnaHzLx1XyXfefR4Vugict/TJihSw7fsOcvuDC1i2eV/o/BvPHc5XbjyL0mKNapvPlAhECtTq7XW894fzqd0T3kXEhy4fy8euOqVTna9JblEiEClAC9ft5o6fLGRPQ/o1gSKDe992Ju+6YFQMkUkclAhECsyTr2zhw7MW09ic/oxAjyL49rurufL0qhgik7goEYgUkAefXct/PLE8dISwAeU9mHlWkZJAAdIVIJECkEg4X56zgi88Hp4ERg3szSMfvJiT+qtX0EKkMwKRPNfYnOATv1rC7CWbQ+dPGN6PH9x2PpUVZazLbGiSJZQIRPLcvU8sbzcJXHHqIP73nRPp3UOHgkKmT18kj63Yso+fvbA+dN4tk0Zy74wzKNEzAgVPiUAkj33tyVdDrwl8/KpTmHn5WD0jIIASgUjeeu71XTyzckda+b9dPZ5/mTI2hogkW+mcUCQPuTtf+f2KtPLhJ/TijkvHxBCRZDMlApE8NOflrSzZtDet/BNvHU9ZiW4RldaUCETyTFNLgq/PfTWt/PQhfZk+YWgMEUm2UyIQyTOz5m9gXchg83dNO5UiDSYvIZQIRPJI3aFmvvXHVWnlbxlbyd+dcmIMEUkuUCIQySPf/8sadtY1ppV/auqpMUQjuUKJQCRP7Nh/iAf+vCatfPqEoZw1vF8MEUmuUCIQyRP/+/QqGhpbWpWVFhufeOv4mCKSXKFEIJIH1u6s5xcvbEgrf9cFoxg5sHcMEUkuUSIQyQPfeGolzYnWfUlUlJXwocv1BLEcmxKBSI5bsnEPv1u6Ja38/X93EgMrymKISHJNpInAzKaa2UozW21md4XMH2lmz5jZS2a21MyuiTIekXzj7nw5pCuJE/uU8T51JSEdFFkiMLNi4H5gGnA6cIuZnd6m2meBh919InAz8O2o4hHJRzWv7eD5NbvTyj965TiNMSAdFuUZwSRgtbuvcfdGYBYwo00dB/oG0/2A8NEzRCRNS8L56u/Tu5I4qbKct1ePiCEiyVXmYZ2Vd8eKzW4Cprr7HcH7W4EL3H1mSp0hwFPACUA5cKW7vxiyrjuBOwGqqqrOmzVrVqdiqquro6KiolPLZoLi65pCi+/Z2ib+7+X0h8dmnlNG9eDOnQ0U2j7sbtkc35QpU1509+qweXGfO94CPOju/2VmFwE/NbMz3T2RWsndHwAeAKiurvbJkyd3amM1NTV0dtlMUHxdU0jxHWxq4TP/9ae08okj+/Pxd1zc6QFnCmkfRiHb42tPlE1DtUDq+enwoCzV+4CHAdz9OaAnUBlhTCJ54afPrad2z4G08k9PO02jjslxizIRLADGmdkYM+tB8mLw7DZ1NgBXAJjZaSQTQfqQSiJyxN6GJu57ZnVa+ZWnDWLSmAExRCS5LrJE4O7NwExgLrCC5N1By8zsHjObHlT7OPBPZrYEeAi4zaO6aCGSJ77zp9fZe6CpVVmRwSfVsZx0UqTXCNx9DjCnTdndKdPLgUuijEEkn2zec4AfPbs2rfym84ZzSlWfGCKSfKAni0VyyDfnvcah5lb3UlBWUsS/XnVKTBFJPlAiEMkRr23bz69f3JRWfvslYxjSr1cMEUm+UCIQyRFfe/JV2vQrR79epXzwspPjCUjyhhKBSA6Yv3Y381ZsTyufOWUs/XqXxhCR5BMlApEs117HcsP69+LWi0bFEJHkGyUCkSw3d9lWXtqwJ638Y1edQs/S4hgiknyjRCCSxdydb85blVZ+6uA+vG3isBgiknykRCCSxZZv2cerW/enlX9q2qkUF6krCekeSgQiWWz24vSe2c8Z0Z/Jp5wYQzSSr5QIRLJUIuE8viQ9Edx43nB1LCfdSolAJEstXP8Gm/cebFVWXGRcc+bgmCKSfKVEIJKlHlvcttd2uHRcpQakl26nRCCShZpaEsx5eUta+YxzhsYQjeQ7JQKRLPTXVTt5o6F1V9M9S4u46nQ1C0n3UyIQyUJhzUJXnFZFRVnco8tKPlIiEMkyDY3NPLV8W1r5jAlqFpJoKBGIZJl5K7bT0NjSqqxvzxIuG69nByQaSgQiWSbsIbJrzhpCWYn6FZJoKBGIZJE9DY386bX07qan624hiZASgUgW+f0rW2lqaT36zKA+ZVwwZmBMEUkhUCIQySJhdwtdN2GoOpiTSCkRiGSJrXsP8sLa3WnleohMoqZEIJIlnli6GW8zJvGYynLOGtYvnoCkYCgRiGSJx0LuFrpuwlD1NCqRUyIQyQKv76jj5dq9aeXT9RCZZIASgUgWCHt24MxhfRk7qCKGaKTQKBGIxMw9fACaGRM0JrFkhhKBSMxeqd3Hmp31rcrM4NoJQ2KKSAqNEoFIzMKeHZg0egBD+vWKIRopREoEIjFqSTiPLw1pFjpHzUKSOZEmAjObamYrzWy1md3VTp23m9lyM1tmZr+IMh6RbDN/7W627TvUqqy02JimcYklgyIb5cLMioH7gauATcACM5vt7stT6owDPg1c4u5vmNmgqOIRyUazl6Q3C112yomcUN4jhmikUEV5RjAJWO3ua9y9EZgFzGhT55+A+939DQB3T+92USRPHWpuYc7LW9PKr9OzA5Jh5m2fae+uFZvdBEx19zuC97cCF7j7zJQ6vwVeAy4BioEvuPuTIeu6E7gToKqq6rxZs2Z1Kqa6ujoqKrL3vmzF1zW5Ft9L25v51qLWzUI9iuF/p/SmrCSep4lzbR9mm2yOb8qUKS+6e3XYvLgHQC0BxgGTgeHAn83sLHffk1rJ3R8AHgCorq72yZMnd2pjNTU1dHbZTFB8XZNr8f36F4uALa3qTDtrKFdfOTGzgaXItX2YbbI9vvZE2TRUC4xIeT88KEu1CZjt7k3uvpbk2cG4CGMSyQr1h5qZtyJkXGL1NCoxiDIRLADGmdkYM+sB3AzMblPntyTPBjCzSuAUYE2EMYlkhT8s38bBpkSrsv69S3nLWI1LLJkXWSJw92ZgJjAXWAE87O7LzOweM5seVJsL7DKz5cAzwL+5+66oYhLJFmEPkV1z1hB6lOjRHsm8SK8RuPscYE6bsrtTph34WPASKQi76xv5y6qdaeUzdLeQxET/fohk2JyXt9CcaH233pB+PTl/9ICYIpJCp0QgkmFhXU5PnzCUIo1LLDFRIhDJoNo9B5i/Ln1cYj1EJnFSIhDJoLBxB04+sZwzhvaNIRqRJCUCkQwKaxaacc4wjUsssYr7yWKRglFbl2D5lvq0co1LLHHTGYFIhjy/pTmtbMLwfoyuLI8hGpE3KRGIZIC78/zm9EQwXQPQSBZQIhDJgMUb97DjQOtnB8zgurM1LrHET4lAJANmh9wtdPHJAxnUt2cM0Yi0pkQgErGWhPP4ki1p5TMmqFlIsoMSgUjEnnt9Fzvr2g5AU8TVGpdYsoQSgUjEwnoanTz+RPr1Ko0hGpF0x0wEZvYhMzshE8GI5JuDTS08uSx9XOIZultIskhHzgiqgAVm9rCZTTU9AinSYTUrd7D/YOvbRst7FHPFaYNiikgk3TETgbt/luTwkT8AbgNWmdl/mtnJEccmkvNmL0lvFrr6jMH0LC2OIRqRcB26RhAMILM1eDUDJwC/NrOvRRibSE7bf7CJeSu2p5VP17jEkmWO2deQmX0EeA+wE/g+yeEkm8ysCFgFfDLaEEVy09xl22hsbj0u8cDyHlwytjKmiETCdaTTuQHADe6+PrXQ3RNmdm00YYnkvrCHyP7+7CGUFutmPckux0wE7v75o8xb0b3hiOSHHfsP8ezq9HGJ1dOoZCP9ayISgTkvb6GlzbjEA3sa547UndiSfZQIRCIQ9hDZhUNKNC6xZCUlApFutnF3A4s27Ekrv3CoxoGS7KREINLNwi4Sj6/qw4g++nOT7KRvpkg3CxuXWM8OSDZTIhDpRq9u3cfKbfvTynW3kGQzJQKRbhR2NnDuyP6MGNA7hmhEOkaJQKSbuDuPhSQC9TQq2U6JQKSbLNrwBrV7DrQqKzK45iyNSyzZTYlApJuEnQ1cMraSE/uUxRCNSMcpEYh0g+aWBL9bGjIusZqFJAdEmgiCgWxWmtlqM7vrKPVuNDM3s+oo4xGJyrOv72JXfWOrsh4lRVx9RlVMEYl0XGSJwMyKgfuBacDpwC1mdnpIvT7AR4AXoopFJGphXUpcceog+vTUuMSS/aI8I5gErHb3Ne7eCMwCZoTUuxf4KnAwwlhEInOwqYW5r4SNS6xnByQ3WHLwsQhWbHYTMNXd7wje3wpc4O4zU+qcC3zG3W80sxrgE+6+MGRddwJ3AlRVVZ03a9asTsVUV1dHRUVFp5bNBMXXNXHFN39rM99efKhVWa8S+NaU3vQofrOTuWzff5D9MSq+zpsyZcqL7h7a/B5bL1jBCGf/TXIc5KNy9weABwCqq6t98uTJndpmTU0NnV02ExRf18QV30M/XQhsa1V27YThvPWKCa3Ksn3/QfbHqPiiEWXTUC0wIuX98KDssD7AmUCNma0DLgRm64Kx5JK9B5p45tUdaeW6W0hySZSJYAEwzszGmFkP4GZg9uGZ7r7X3SvdfbS7jwaeB6aHNQ2JZKu5r2ylsaX1uMSVFWVcdPLAmCISOX6RJQJ3bwZmAnOBFcDD7r7MzO4xs+lRbVckkx5bkn630LVnD6FYA9BIDon0GoG7zwHmtCm7u526k6OMRaS7bd93kL+9viutXHcLSa7Rk8UinfTE0i20velu5IDenDOifzwBiXSSEoFIJz0WMhLZ9AlDMVOzkOQWJQKRTli3s54lG9PHJVazkOQiJQKRTggbl/i0IX0ZV9UnhmhEukaJQOQ4JQegSb9bSGcDkquUCESO0/It+3h9R31a+XUal1hylBKByHEKG5f4/NEnMKx/rxiiEek6JQKR45BIeOj1genqUkJymBKByHFYuP4Ntuxt3WN6SZHx9xqXWHKYEoHIcQi7SHzpuEoGlPeIIRqR7qFEINJBjc0Jfvdy+rjE03W3kOQ4JQKRDvrr6h3saWhqVdaztIirTh8cU0Qi3UOJQKSDHgu5W+jK06qoKIttfCeRbqFEINIBDY3N/GH5trRyDUAj+UCJQKQD5q3YTkNjS6uyvj1L+LtTKmOKSKT7KBGIdMDskLuFrjlrCGUlxTFEI9K9lAhEjmFPQyN/ei19XGLdLST5QolA5Bh+/8pWmlpaj0BT1beMC8ZoXGLJD0oEIsfw6Eth4xIP1bjEkjeUCESO4vk1u5i/dndaubqclnyiRCDSDnfnK79/Na38pBPLOWtYvxgiEomGEoFIO558ZSuLQ4ajnDllrMYllryiRCASoqklwdfmrkwrP21IX96mh8gkzygRiIT45YKNrN2ZPgrZp6aOp0gXiSXPKBGItFF/qJlvzluVVn7xyQO57JQTY4hIJFpKBCJt/OCva9lZdyit/K5pp+ragOQlJQKRFDvrDvG9P72eVn7t2UM4e3j/GCISiZ4SgUiK+55eTX2bzuVKioxPvHV8TBGJRE+JQCSwflc9P39hfVr5uy4YyejK8hgiEskMJQKRwDeeei2tT6HyHsV86IpxMUUkkhmRJgIzm2pmK81stZndFTL/Y2a23MyWmtkfzWxUlPGItGfppj08viR9BLI7/+5kKivKYohIJHMiSwRmVgzcD0wDTgduMbPT21R7Cah297OBXwNfiyoekfa015VEZUUZd1w6JoaIRDIryjOCScBqd1/j7o3ALGBGagV3f8bdG4K3zwPDI4xHJNSfV+3kb6/vSiv/yJXjKNd4xFIAzN2PXaszKza7CZjq7ncE728FLnD3me3Uvw/Y6u5fDJl3J3AnQFVV1XmzZs3qVEx1dXVUVFR0atlMUHxd05n4Eu58/m8H2bg/0aq8qrfxpbf0oqQbnyLO9v0H2R+j4uu8KVOmvOju1WHzsuLfHTN7N1ANXBY2390fAB4AqK6u9smTJ3dqOzU1NXR22UxQfF3TmfgefWkTG/cvSSv//PUTufKsId0UWVK27z/I/hgVXzSiTAS1wIiU98ODslbM7ErgM8Bl7p7+OKdIRA42tfCNua+llU8Y0Z9pZw6OISKReER5jWABMM7MxphZD+BmYHZqBTObCHwPmO7u2yOMRSTNz55fT+2eA2nln1ZXElJgIksE7t4MzATmAiuAh919mZndY2bTg2pfByqAX5nZYjOb3c7qRLrV3gNN3PfM6rTyy08dxIUnaSxiKSyRXiNw9znAnDZld6dMXxnl9kXa870/vc6ehqZWZWbwyanqSkIKj54sloKzde9Bfvjs2rTyG88dzqmD+8YQkUi8lAik4Hxz3mscbGp9u2iPkiL+9apTYopIJF5KBFJQVm3bz8MLN6aV337xaIb17xVDRCLxUyKQgvK1uStJtHmGsm/PEj44+eR4AhLJAkoEUjAWrtvNH5ZvSyv/lylj6d+7RwwRiWQHJQIpCO7Ol0M6lhvSryfvvXh05gMSySJKBFIQnlq+jRfXv5FW/rGrTqFnaXEMEYlkDyUCyXvNLQm+9mT62cD4qj7ccK46vBVRIpC8N2vBRl7fUZ9W/qlp4ynuxt5FRXKVEoHktYcXbuTzs5ellV8wZgBTxg+KISKR7JMV3VCLdDd353/+uJr/Ny+9d1GAu9SxnMgRSgSSd5pbEnzusVd4aH76g2MAM84ZysSRJ2Q4KpHspUQgeaWhsZmZv3iJp18N79X8opMG8qXrz8pwVCLZTYlA8sa+Q87NDzzP0k17Q+dPnzCUr//D2ZSV6HZRkVRKBJIX1u6s597nD7DjQEPo/PdfdhKfuvpUinSXkEgaJQLJeS9teIP3/Xghuw942jwz+MJ1Z+jpYZGjUCKQnPaH5dv40EOL0rqVBigrKeJbN5/D1DO7dxB6kXyjRCA562fPr+fux15J600UoH/vUr7/nmqqRw/IfGAiOUaJQHKOu/ONp1Zy/zOvh84ffkIvHrx9EmMHVWQ4MpHcpEQgOaWxOcFdjyzlkUW1ofPPGNqXH91+PoP69MxwZCK5S4lAcsb+g038888X8ZdVO0Pnn1lZzKz3X0RFmb7WIsdDfzGSE7btO8jtP1rA8i37QuffdN5wpg7crSQg0gnqdE6y2hv1jfz0uXXc8O2/tZsEPnz5WL5+09mU6BkBkU7Rv0+SdQ41t/D0iu088lItNSu309QSclsQUGTwxbedxTsvGJnhCEXyixKBZAV3Z+H6N3hkUS2/W7qZfQebj1q/V2kx971zIlecVpWhCEXylxKBxGrtznoeXbSJRxfXsnH3gQ4tM7C8Bz+47XzOGdE/4uhECoMSgWTc7vpGnli6mUcW1bJ4457jWvb80Sfw9ZsmMLqyPKLoRAqPEoFkRENjMzUrd/DIomS7f3PY48DtGNSnjLdNHMb1E4dx2pC+EUYpUpiUCKTb7DvYxIZdDazbVc/6XQ2s31XPul0NbNjVwNZ9B49rXb1Ki5l65mBuOHcYF59cqbGFRSKkRCAd5u7sqjvE+t3BQX5nAxt2v3ng313f2KX1FxlcMraS6ycO4+ozBlOuZwJEMkJ/aXmuJeE0tW8xbnMAAAkGSURBVCRoTjiNzQnqDzVTl/o62NyqLDndkjId1GlsZvveBg7MndftMZ46uA83nDuMGecMo6qvuoYQybRIE4GZTQW+BRQD33f3r7SZXwb8BDgP2AW8w93XdWcMG3c38L0/Jzsn21x7iHl7XsZDmqfbFoXVAT9S7g4eLJWcblN+uB7J/6QPTyccEsECCffglayzY+dBfrx2/pE6h9eVSLxZt6nFaU4kaG558wB/eDr1oN/c4jQlEu38HvGr6lvGjHPU7i+SDSJLBGZWDNwPXAVsAhaY2Wx3X55S7X3AG+4+1sxuBr4KvKM749hV38jPnt/wZsHGDe1XzgY7dsQdQSTMYGi/Xlxw0gCun6h2f5FsEuUZwSRgtbuvATCzWcAMIDURzAC+EEz/GrjPzMw9W/+PlaMpKTKGn9CLUQPLGT2wNyODn6MGljNiQC+NFSySpaJMBMOAjSnvNwEXtFfH3ZvNbC8wEGjVvaSZ3QncCVBVVUVNTU2Hg1izt+V445ajKC2CE3sbVb2LGNTbGNS7iKrg58CeFvyX35B8Ne+EbbBpW/LDj1pdXd1xfTcyLdvjg+yPUfFFIycuFrv7A8ADANXV1T558uQOL3vCxj3w3LMRRZb9zKC0qIiSYqO0uIiKshLKy4qDnyVUBK/y1J89S6goK6a8x+HpZPnLi+Yz/aopWTsAfE1NDcfz3ci0bI8Psj9GxReNKBNBLTAi5f3woCysziYzKwH6kbxo3G2GndCLe2ecAcBrq1ZxyrhxyRmWfjBrWxJSBcOOlFtKHcOOrCBZbkfWZ/ZmvSIzzIwiS04X2Zt1ly17hQlnnxXMT5al1ikyKCkuorTYKClK/iwuSh7gS1LKSoqLKAnKu7MdfmNZUdYmARHpvCgTwQJgnJmNIXnAvxl4Z5s6s4H3As8BNwFPd/f1gcqKMm69aDQANYfWMTmYzkY9drzK5FPViZqIZFZkiSBo858JzCV5++gP3X2Zmd0DLHT32cAPgJ+a2WpgN8lkISIiGRTpNQJ3nwPMaVN2d8r0QeAfooxBRESOTiOUiYgUOCUCEZECp0QgIlLglAhERAqc5VpvDma2A1jfycUrafPUcpZRfF2j+Lou22NUfJ03yt1PDJuRc4mgK8xsobtXxx1HexRf1yi+rsv2GBVfNNQ0JCJS4JQIREQKXKElggfiDuAYFF/XKL6uy/YYFV8ECuoagYiIpCu0MwIREWlDiUBEpMDlXSIws38ws2VmljCz6jbzPm1mq81spZld3c7yY8zshaDeL82sR4Sx/tLMFgevdWa2uJ1668zs5aDewqjiCdnuF8ysNiXGa9qpNzXYp6vN7K4Mxvd1M3vVzJaa2aNm1r+dehndf8faH2ZWFnz2q4Pv2uioY0rZ9ggze8bMlgd/Jx8JqTPZzPamfO53h60rwhiP+nlZ0v8E+2+pmZ2bwdjGp+yXxWa2z8w+2qZOrPuvU9w9r17AacB4oAaoTik/HVgClAFjgNeB4pDlHwZuDqa/C3wwQ3H/F3B3O/PWAZUx7MsvAJ84Rp3iYF+eBPQI9vHpGYrvrUBJMP1V4Ktx77+O7A/gn4HvBtM3A7/M4Gc6BDg3mO4DvBYS32TgiUx/3zr6eQHXAL8nOQbUhcALMcVZDGwl+aBW1uy/zrzy7ozA3Ve4+8qQWTOAWe5+yN3XAquBSakVzMyAy4FfB0U/Bt4WZbwp23078FDU24rAJGC1u69x90ZgFsl9HTl3f8rdm4O3z5McBS9uHdkfM0h+tyD5Xbsi+A5Ezt23uPuiYHo/sILk2OG5ZAbwE096HuhvZkNiiOMK4HV372xPB1kj7xLBUQwDNqa830T6H8BAYE/KwSWsThQuBba5+6p25jvwlJm9aGZ3ZiCeVDOD0+8fmtkJIfM7sl8z4R9J/pcYJpP7ryP740id4Lu2l+R3L6OCJqmJwAshsy8ysyVm9nszOyOjgR3788qW79zNtP/PW5z777jlxOD1bZnZPGBwyKzPuPtjmY7naDoY6y0c/WzgLe5ea2aDgD+Y2avu/ueo4wO+A9xL8g/zXpLNV//YHdvtqI7sPzP7DNAM/Lyd1US2/3KVmVUAvwE+6u772sxeRLK5oy64LvRbYFwGw8v6zyu4djgd+HTI7Lj333HLyUTg7ld2YrFaYETK++FBWapdJE8zS4L/1MLqHJdjxWpmJcANwHlHWUdt8HO7mT1KsvmhW/4wOrovzez/gCdCZnVkv3ZaB/bfbcC1wBUeNNCGrCOy/ReiI/vjcJ1Nweffj+R3LyPMrJRkEvi5uz/Sdn5qYnD3OWb2bTOrdPeMdKbWgc8r0u9cB00DFrn7trYz4t5/nVFITUOzgZuDOzbGkMzQ81MrBAeSZ4CbgqL3AlGfYVwJvOrum8Jmmlm5mfU5PE3yAukrEcd0eNup7a7Xt7PdBcA4S95t1YPk6fLsDMU3FfgkMN3dG9qpk+n915H9MZvkdwuS37Wn20ti3S24FvEDYIW7/3c7dQYfvmZhZpNIHicykqg6+HnNBt4T3D10IbDX3bdkIr4U7Z7Fx7n/Oi3uq9Xd/SJ5wNoEHAK2AXNT5n2G5B0dK4FpKeVzgKHB9EkkE8Rq4FdAWcTxPgh8oE3ZUGBOSjxLgtcykk0imdqXPwVeBpaS/OMb0ja+4P01JO8+eT3D8a0m2Va8OHh9t218cey/sP0B3EMyYQH0DL5bq4Pv2kkZ3GdvIdnUtzRlv10DfODw9xCYGeyrJSQvwl+cwfhCP6828Rlwf7B/Xybl7sAMxVhO8sDeL6UsK/ZfZ1/qYkJEpMAVUtOQiIiEUCIQESlwSgQiIgVOiUBEpMApEYiIFDglAhGRAqdEICJS4JQIRLrIzM4POubrGTwZu8zMzow7LpGO0gNlIt3AzL5I8onhXsAmd/9yzCGJdJgSgUg3CPoVWgAcJNmlQEvMIYl0mJqGRLrHQKCC5KhfPWOOReS46IxApBuY2WySo5GNIdk538yYQxLpsJwcj0Akm5jZe4Amd/+FmRUDfzOzy9396bhjE+kInRGIiBQ4XSMQESlwSgQiIgVOiUBEpMApEYiIFDglAhGRAqdEICJS4JQIREQK3P8H/g1mOUfFkXEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "\n",
    "plt.plot(range(-10,10), [1/(1+exp(-x)) for x in range(-10,10)],\n",
    "         linewidth=5)\n",
    "plt.title('The sigmoid function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can easily incorporate a sigmoid layer after our output layer, so both $y_1,y_2$ lie inside $[0,1]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "activation_11 (Activation)   (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Activation('relu', input_shape=[len(Xdf.keys())]), \n",
    "    tf.keras.layers.Dense(2, use_bias=False), \n",
    "    tf.keras.layers.Activation('sigmoid') ## THIS IS THE SIGMOID LAYER\n",
    "])\n",
    "\n",
    "# Specify stocastic-gradient descend, MSE loss, and MSE as metric\n",
    "NN_model2.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "\n",
    "NN_model2.build()\n",
    "NN_model2.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our new network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 32 samples\n",
      "Epoch 1/1000\n",
      "128/128 [==============================] - 0s 3ms/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 2/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 3/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 4/1000\n",
      "128/128 [==============================] - 0s 371us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 5/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 6/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 7/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 8/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 9/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 10/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 11/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 12/1000\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 13/1000\n",
      "128/128 [==============================] - 0s 436us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 14/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 15/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 16/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 17/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 18/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 19/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 20/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 21/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 22/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 23/1000\n",
      "128/128 [==============================] - 0s 370us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 24/1000\n",
      "128/128 [==============================] - 0s 401us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 25/1000\n",
      "128/128 [==============================] - 0s 453us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 26/1000\n",
      "128/128 [==============================] - 0s 415us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 27/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 28/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 29/1000\n",
      "128/128 [==============================] - 0s 378us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 30/1000\n",
      "128/128 [==============================] - 0s 468us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 31/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 32/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 33/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 34/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 35/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 36/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 37/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 38/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 39/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 40/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 41/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 42/1000\n",
      "128/128 [==============================] - 0s 402us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 43/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 44/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 45/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 46/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 47/1000\n",
      "128/128 [==============================] - 0s 377us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 48/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 49/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 50/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 51/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 52/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 53/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 54/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 55/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 56/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 57/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 58/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 59/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "128/128 [==============================] - 0s 388us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 61/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 62/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 63/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 64/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 65/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 66/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 67/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 68/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 69/1000\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 70/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 71/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 72/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 73/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 74/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 75/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 76/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 77/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 78/1000\n",
      "128/128 [==============================] - 0s 272us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 79/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 80/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 81/1000\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 82/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 83/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 84/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 85/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 86/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 87/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 88/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 89/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 90/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 91/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 92/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 93/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 94/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 95/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 96/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 97/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 98/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 99/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 100/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 101/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 102/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 103/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 104/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 105/1000\n",
      "128/128 [==============================] - 0s 387us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 106/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 107/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 108/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 109/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 110/1000\n",
      "128/128 [==============================] - 0s 484us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 111/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 112/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 113/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 114/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 115/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 116/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 117/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 118/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000\n",
      "128/128 [==============================] - 0s 381us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 120/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 121/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 122/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 123/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 124/1000\n",
      "128/128 [==============================] - 0s 375us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 125/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 126/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 127/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 128/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 129/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 130/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 131/1000\n",
      "128/128 [==============================] - 0s 248us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 132/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 133/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 134/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 135/1000\n",
      "128/128 [==============================] - 0s 261us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 136/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 137/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 138/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 139/1000\n",
      "128/128 [==============================] - 0s 381us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 140/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 141/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 142/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 143/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 144/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 145/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 146/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 147/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 148/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 149/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 150/1000\n",
      "128/128 [==============================] - 0s 263us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 151/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 152/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 153/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 154/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 155/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 156/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 157/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 158/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 159/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 160/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 161/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 162/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 163/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 164/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 165/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 166/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 167/1000\n",
      "128/128 [==============================] - 0s 263us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 168/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 169/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 170/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 171/1000\n",
      "128/128 [==============================] - 0s 260us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 172/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 173/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 174/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 175/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 176/1000\n",
      "128/128 [==============================] - 0s 255us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 178/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 179/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 180/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 181/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 182/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 183/1000\n",
      "128/128 [==============================] - 0s 365us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 184/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 185/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 186/1000\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 187/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 188/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 189/1000\n",
      "128/128 [==============================] - 0s 260us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 190/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 191/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 192/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 193/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 194/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 195/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 196/1000\n",
      "128/128 [==============================] - 0s 273us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 197/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 198/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 199/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 200/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 201/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 202/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 203/1000\n",
      "128/128 [==============================] - 0s 469us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 204/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 205/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 206/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 207/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 208/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 209/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 210/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 211/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 212/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 213/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 214/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 215/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 216/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 217/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 218/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 219/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 220/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 221/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 222/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 223/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 224/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 225/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 226/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 227/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 228/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 229/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 230/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 231/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 232/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 233/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 234/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 335us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 236/1000\n",
      "128/128 [==============================] - 0s 403us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 237/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 238/1000\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 239/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 240/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 241/1000\n",
      "128/128 [==============================] - 0s 402us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 242/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 243/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 244/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 245/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 246/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 247/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 248/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 249/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 250/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 251/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 252/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 253/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 254/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 255/1000\n",
      "128/128 [==============================] - 0s 423us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 256/1000\n",
      "128/128 [==============================] - 0s 408us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 257/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 258/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 259/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 260/1000\n",
      "128/128 [==============================] - 0s 422us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 261/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 262/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 263/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 264/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 265/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 266/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 267/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 268/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 269/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 270/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 271/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 272/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 273/1000\n",
      "128/128 [==============================] - 0s 528us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 274/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 275/1000\n",
      "128/128 [==============================] - 0s 388us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 276/1000\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 277/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 278/1000\n",
      "128/128 [==============================] - 0s 383us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 279/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 280/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 281/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 282/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 283/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 284/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 285/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 286/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 287/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 288/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 289/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 290/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 291/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 292/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 359us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 294/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 295/1000\n",
      "128/128 [==============================] - 0s 405us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 296/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 297/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 298/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 299/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 300/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 301/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 302/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 303/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 304/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 0.4497 - mse: 0.4497 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 305/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 306/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 307/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 308/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 309/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 310/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 311/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 312/1000\n",
      "128/128 [==============================] - 0s 375us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 313/1000\n",
      "128/128 [==============================] - 0s 417us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 314/1000\n",
      "128/128 [==============================] - 0s 364us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 315/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 316/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 317/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 318/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 319/1000\n",
      "128/128 [==============================] - 0s 456us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 320/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 321/1000\n",
      "128/128 [==============================] - 0s 497us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 322/1000\n",
      "128/128 [==============================] - 0s 428us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 323/1000\n",
      "128/128 [==============================] - 0s 370us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 324/1000\n",
      "128/128 [==============================] - 0s 475us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 325/1000\n",
      "128/128 [==============================] - 0s 383us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 326/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 327/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 328/1000\n",
      "128/128 [==============================] - 0s 392us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 329/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 330/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 331/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 332/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 333/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 334/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 335/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 336/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 337/1000\n",
      "128/128 [==============================] - 0s 429us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 338/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 339/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 340/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 341/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 342/1000\n",
      "128/128 [==============================] - 0s 398us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 343/1000\n",
      "128/128 [==============================] - 0s 395us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 344/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 345/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 346/1000\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 347/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 348/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 349/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 350/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 351/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 352/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 353/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 354/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 355/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 356/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 357/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 358/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 359/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 360/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 361/1000\n",
      "128/128 [==============================] - 0s 400us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 362/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 363/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 364/1000\n",
      "128/128 [==============================] - 0s 399us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 365/1000\n",
      "128/128 [==============================] - 0s 396us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 366/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 367/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 368/1000\n",
      "128/128 [==============================] - 0s 423us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 369/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 370/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 371/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 372/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 373/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 374/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 375/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 376/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 377/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 378/1000\n",
      "128/128 [==============================] - 0s 479us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 379/1000\n",
      "128/128 [==============================] - 0s 419us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 380/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 381/1000\n",
      "128/128 [==============================] - 0s 449us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 382/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 383/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 384/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 385/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 386/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 387/1000\n",
      "128/128 [==============================] - 0s 378us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 388/1000\n",
      "128/128 [==============================] - 0s 418us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 389/1000\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 390/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 391/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 392/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 393/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 394/1000\n",
      "128/128 [==============================] - 0s 399us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 395/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 396/1000\n",
      "128/128 [==============================] - 0s 359us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 397/1000\n",
      "128/128 [==============================] - 0s 411us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 398/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 399/1000\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 400/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 401/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 402/1000\n",
      "128/128 [==============================] - 0s 377us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 403/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 404/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 405/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 406/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 407/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 408/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 410/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 411/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 412/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 413/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 414/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 415/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 416/1000\n",
      "128/128 [==============================] - 0s 391us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 417/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 418/1000\n",
      "128/128 [==============================] - 0s 282us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 419/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 420/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 421/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 422/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 423/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 424/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 425/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 426/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 427/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 428/1000\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 429/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 430/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 431/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 432/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 433/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 434/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 435/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 436/1000\n",
      "128/128 [==============================] - 0s 364us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 437/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 438/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 439/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 440/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 441/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4999 - val_mse: 0.4999\n",
      "Epoch 442/1000\n",
      "128/128 [==============================] - 0s 261us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 443/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 444/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 445/1000\n",
      "128/128 [==============================] - 0s 266us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 446/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 447/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 448/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 449/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 450/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 451/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 452/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 453/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 454/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 455/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 456/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 457/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 458/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 459/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 460/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 461/1000\n",
      "128/128 [==============================] - 0s 267us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 462/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 463/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 464/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 465/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 466/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 467/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 468/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 469/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 470/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 471/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 472/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 473/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 474/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 475/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 476/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 477/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 478/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4496 - mse: 0.4496 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 479/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 480/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 481/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 482/1000\n",
      "128/128 [==============================] - 0s 280us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 483/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 484/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 485/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 486/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 487/1000\n",
      "128/128 [==============================] - 0s 274us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 488/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 489/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 490/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 491/1000\n",
      "128/128 [==============================] - 0s 395us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 492/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 493/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 494/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 495/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 496/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 497/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 498/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 499/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 500/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 501/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 502/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 503/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 504/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 505/1000\n",
      "128/128 [==============================] - 0s 375us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 506/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 507/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 508/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 509/1000\n",
      "128/128 [==============================] - 0s 383us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 510/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 511/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 512/1000\n",
      "128/128 [==============================] - 0s 453us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 513/1000\n",
      "128/128 [==============================] - 0s 416us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 514/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 515/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 516/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 517/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 518/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 519/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 520/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 521/1000\n",
      "128/128 [==============================] - 0s 377us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 522/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 523/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 524/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 525/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 526/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 527/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 528/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 529/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 530/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 531/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 532/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 533/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 534/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 535/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 536/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 537/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 538/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 539/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 540/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 541/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 542/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 543/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 544/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 545/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 546/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 547/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 548/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 549/1000\n",
      "128/128 [==============================] - 0s 359us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 550/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 551/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 552/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 553/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 554/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 555/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 556/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 557/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 558/1000\n",
      "128/128 [==============================] - 0s 378us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 559/1000\n",
      "128/128 [==============================] - 0s 393us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 560/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 561/1000\n",
      "128/128 [==============================] - 0s 411us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 562/1000\n",
      "128/128 [==============================] - 0s 392us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 563/1000\n",
      "128/128 [==============================] - 0s 418us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 564/1000\n",
      "128/128 [==============================] - 0s 352us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 565/1000\n",
      "128/128 [==============================] - 0s 384us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 566/1000\n",
      "128/128 [==============================] - 0s 375us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 567/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 568/1000\n",
      "128/128 [==============================] - 0s 358us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 569/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 570/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 571/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 572/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 573/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 574/1000\n",
      "128/128 [==============================] - 0s 335us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 575/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 576/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 577/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 578/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 579/1000\n",
      "128/128 [==============================] - 0s 429us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 580/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 581/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 582/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 507us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 584/1000\n",
      "128/128 [==============================] - 0s 391us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 585/1000\n",
      "128/128 [==============================] - 0s 391us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 586/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 587/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 588/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 589/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 590/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 591/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 592/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 593/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 594/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 595/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 596/1000\n",
      "128/128 [==============================] - 0s 418us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 597/1000\n",
      "128/128 [==============================] - 0s 381us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 598/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 599/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 600/1000\n",
      "128/128 [==============================] - 0s 426us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 601/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 602/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 603/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 604/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 605/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 606/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 607/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 608/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 609/1000\n",
      "128/128 [==============================] - 0s 449us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 610/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 611/1000\n",
      "128/128 [==============================] - 0s 256us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 612/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 613/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 614/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 615/1000\n",
      "128/128 [==============================] - 0s 394us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 616/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 617/1000\n",
      "128/128 [==============================] - 0s 358us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 618/1000\n",
      "128/128 [==============================] - 0s 381us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 619/1000\n",
      "128/128 [==============================] - 0s 398us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 620/1000\n",
      "128/128 [==============================] - 0s 398us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 621/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 622/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 623/1000\n",
      "128/128 [==============================] - 0s 406us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 624/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 625/1000\n",
      "128/128 [==============================] - 0s 380us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 626/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 627/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 628/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 629/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 630/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 631/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 632/1000\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 633/1000\n",
      "128/128 [==============================] - 0s 382us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 634/1000\n",
      "128/128 [==============================] - 0s 450us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 635/1000\n",
      "128/128 [==============================] - 0s 481us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 636/1000\n",
      "128/128 [==============================] - 0s 368us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 637/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 638/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 639/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 640/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 641/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 360us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 642/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 643/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 644/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 645/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 646/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 647/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 0.4495 - mse: 0.4495 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 648/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 649/1000\n",
      "128/128 [==============================] - 0s 392us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 650/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 651/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 652/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 653/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 654/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 655/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 656/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 657/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 658/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 659/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 660/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 661/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 662/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 663/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 664/1000\n",
      "128/128 [==============================] - 0s 359us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 665/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 666/1000\n",
      "128/128 [==============================] - 0s 477us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 667/1000\n",
      "128/128 [==============================] - 0s 612us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 668/1000\n",
      "128/128 [==============================] - 0s 436us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 669/1000\n",
      "128/128 [==============================] - 0s 396us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 670/1000\n",
      "128/128 [==============================] - 0s 395us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 671/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 672/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 673/1000\n",
      "128/128 [==============================] - 0s 355us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 674/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 675/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 676/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 677/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 678/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 679/1000\n",
      "128/128 [==============================] - 0s 348us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 680/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 681/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 682/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 683/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 684/1000\n",
      "128/128 [==============================] - 0s 410us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 685/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 686/1000\n",
      "128/128 [==============================] - 0s 397us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 687/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 688/1000\n",
      "128/128 [==============================] - 0s 439us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 689/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 690/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 691/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 692/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 693/1000\n",
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 694/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 695/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 696/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 697/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 698/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 699/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 700/1000\n",
      "128/128 [==============================] - 0s 375us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 701/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 702/1000\n",
      "128/128 [==============================] - 0s 425us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 703/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 704/1000\n",
      "128/128 [==============================] - 0s 367us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 705/1000\n",
      "128/128 [==============================] - 0s 333us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 706/1000\n",
      "128/128 [==============================] - 0s 327us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 707/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 708/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 709/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 710/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 711/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 712/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 713/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 714/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 715/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 716/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 717/1000\n",
      "128/128 [==============================] - 0s 358us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 718/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 719/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 720/1000\n",
      "128/128 [==============================] - 0s 343us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 721/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 722/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 723/1000\n",
      "128/128 [==============================] - 0s 377us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 724/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 725/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 726/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 727/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 728/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 729/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 730/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 731/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 732/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 733/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 734/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 735/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 736/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 737/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 738/1000\n",
      "128/128 [==============================] - 0s 346us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 739/1000\n",
      "128/128 [==============================] - 0s 352us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 740/1000\n",
      "128/128 [==============================] - 0s 396us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 741/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 742/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 743/1000\n",
      "128/128 [==============================] - 0s 339us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 744/1000\n",
      "128/128 [==============================] - 0s 357us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 745/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 746/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 747/1000\n",
      "128/128 [==============================] - 0s 285us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 748/1000\n",
      "128/128 [==============================] - 0s 319us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 749/1000\n",
      "128/128 [==============================] - 0s 360us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 750/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 751/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 752/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 753/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 754/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 755/1000\n",
      "128/128 [==============================] - 0s 388us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 756/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 758/1000\n",
      "128/128 [==============================] - 0s 412us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 759/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 760/1000\n",
      "128/128 [==============================] - 0s 265us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 761/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 762/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 763/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 764/1000\n",
      "128/128 [==============================] - 0s 260us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 765/1000\n",
      "128/128 [==============================] - 0s 268us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 766/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 767/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 768/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 769/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 770/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 771/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 772/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 773/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 774/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 775/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 776/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 777/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 778/1000\n",
      "128/128 [==============================] - 0s 386us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 779/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 780/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 781/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 782/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 783/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 784/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 785/1000\n",
      "128/128 [==============================] - 0s 270us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 786/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 787/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 788/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 789/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 790/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 791/1000\n",
      "128/128 [==============================] - 0s 276us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 792/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 793/1000\n",
      "128/128 [==============================] - 0s 374us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 794/1000\n",
      "128/128 [==============================] - 0s 419us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 795/1000\n",
      "128/128 [==============================] - 0s 379us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 796/1000\n",
      "128/128 [==============================] - 0s 534us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 797/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 798/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 799/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 800/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 801/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 802/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 803/1000\n",
      "128/128 [==============================] - 0s 262us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 804/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 805/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 806/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 807/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 808/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 809/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 810/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 811/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 812/1000\n",
      "128/128 [==============================] - 0s 354us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 813/1000\n",
      "128/128 [==============================] - 0s 390us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 814/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 815/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 816/1000\n",
      "128/128 [==============================] - 0s 378us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 817/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 818/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 819/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 820/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 821/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 822/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 823/1000\n",
      "128/128 [==============================] - 0s 317us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 824/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 825/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 826/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 827/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 828/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 829/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4494 - mse: 0.4494 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 830/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 831/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 832/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 833/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 834/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 835/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 836/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 837/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 838/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 839/1000\n",
      "128/128 [==============================] - 0s 313us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 840/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 841/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 842/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 843/1000\n",
      "128/128 [==============================] - 0s 318us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 844/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 845/1000\n",
      "128/128 [==============================] - 0s 291us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 846/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 847/1000\n",
      "128/128 [==============================] - 0s 323us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 848/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 849/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 850/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 851/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 852/1000\n",
      "128/128 [==============================] - 0s 389us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 853/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 854/1000\n",
      "128/128 [==============================] - 0s 375us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 855/1000\n",
      "128/128 [==============================] - 0s 431us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 856/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 857/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 858/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 859/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 860/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 861/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 862/1000\n",
      "128/128 [==============================] - ETA: 0s - loss: 0.3993 - mse: 0.399 - 0s 287us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 863/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 864/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 865/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 866/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 867/1000\n",
      "128/128 [==============================] - 0s 289us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 868/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 869/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 870/1000\n",
      "128/128 [==============================] - 0s 410us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 871/1000\n",
      "128/128 [==============================] - 0s 345us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 872/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 873/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 373us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 874/1000\n",
      "128/128 [==============================] - 0s 385us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 875/1000\n",
      "128/128 [==============================] - 0s 341us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 876/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 877/1000\n",
      "128/128 [==============================] - 0s 312us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 878/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 879/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 880/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 881/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 882/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 883/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 884/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 885/1000\n",
      "128/128 [==============================] - 0s 286us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 886/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 887/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 888/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 889/1000\n",
      "128/128 [==============================] - 0s 400us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 890/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 891/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 892/1000\n",
      "128/128 [==============================] - 0s 277us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 893/1000\n",
      "128/128 [==============================] - 0s 344us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 894/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 895/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 896/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 897/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 898/1000\n",
      "128/128 [==============================] - 0s 302us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 899/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 900/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 901/1000\n",
      "128/128 [==============================] - 0s 320us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 902/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 903/1000\n",
      "128/128 [==============================] - 0s 321us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 904/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 905/1000\n",
      "128/128 [==============================] - 0s 293us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 906/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 907/1000\n",
      "128/128 [==============================] - 0s 288us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 908/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 909/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 910/1000\n",
      "128/128 [==============================] - 0s 342us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 911/1000\n",
      "128/128 [==============================] - 0s 295us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 912/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 913/1000\n",
      "128/128 [==============================] - 0s 322us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 914/1000\n",
      "128/128 [==============================] - 0s 331us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 915/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 916/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 917/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 918/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 919/1000\n",
      "128/128 [==============================] - 0s 324us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 920/1000\n",
      "128/128 [==============================] - 0s 306us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 921/1000\n",
      "128/128 [==============================] - 0s 278us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 922/1000\n",
      "128/128 [==============================] - 0s 279us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 923/1000\n",
      "128/128 [==============================] - 0s 294us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 924/1000\n",
      "128/128 [==============================] - 0s 307us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 925/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 926/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 927/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 928/1000\n",
      "128/128 [==============================] - 0s 336us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 929/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 930/1000\n",
      "128/128 [==============================] - 0s 376us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 931/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 406us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 932/1000\n",
      "128/128 [==============================] - 0s 503us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 933/1000\n",
      "128/128 [==============================] - 0s 372us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 934/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 935/1000\n",
      "128/128 [==============================] - 0s 309us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 936/1000\n",
      "128/128 [==============================] - 0s 340us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4998 - val_mse: 0.4998\n",
      "Epoch 937/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 938/1000\n",
      "128/128 [==============================] - 0s 363us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 939/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 940/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 941/1000\n",
      "128/128 [==============================] - 0s 350us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 942/1000\n",
      "128/128 [==============================] - 0s 353us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 943/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 944/1000\n",
      "128/128 [==============================] - 0s 310us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 945/1000\n",
      "128/128 [==============================] - 0s 421us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 946/1000\n",
      "128/128 [==============================] - 0s 361us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 947/1000\n",
      "128/128 [==============================] - 0s 325us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 948/1000\n",
      "128/128 [==============================] - 0s 369us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 949/1000\n",
      "128/128 [==============================] - 0s 366us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 950/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 951/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 952/1000\n",
      "128/128 [==============================] - 0s 292us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 953/1000\n",
      "128/128 [==============================] - 0s 351us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 954/1000\n",
      "128/128 [==============================] - 0s 284us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 955/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 956/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 957/1000\n",
      "128/128 [==============================] - 0s 314us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 958/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 959/1000\n",
      "128/128 [==============================] - 0s 338us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 960/1000\n",
      "128/128 [==============================] - 0s 308us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 961/1000\n",
      "128/128 [==============================] - 0s 326us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 962/1000\n",
      "128/128 [==============================] - 0s 311us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 963/1000\n",
      "128/128 [==============================] - 0s 349us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 964/1000\n",
      "128/128 [==============================] - 0s 415us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 965/1000\n",
      "128/128 [==============================] - 0s 356us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 966/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 967/1000\n",
      "128/128 [==============================] - 0s 398us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 968/1000\n",
      "128/128 [==============================] - 0s 419us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 969/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 970/1000\n",
      "128/128 [==============================] - 0s 301us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 971/1000\n",
      "128/128 [==============================] - 0s 299us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 972/1000\n",
      "128/128 [==============================] - 0s 304us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 973/1000\n",
      "128/128 [==============================] - 0s 328us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 974/1000\n",
      "128/128 [==============================] - 0s 269us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 975/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 976/1000\n",
      "128/128 [==============================] - 0s 330us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 977/1000\n",
      "128/128 [==============================] - 0s 300us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 978/1000\n",
      "128/128 [==============================] - 0s 347us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 979/1000\n",
      "128/128 [==============================] - 0s 329us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 980/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 981/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 982/1000\n",
      "128/128 [==============================] - 0s 392us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 983/1000\n",
      "128/128 [==============================] - 0s 422us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 984/1000\n",
      "128/128 [==============================] - 0s 271us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 985/1000\n",
      "128/128 [==============================] - 0s 315us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 986/1000\n",
      "128/128 [==============================] - 0s 332us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 987/1000\n",
      "128/128 [==============================] - 0s 337us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 988/1000\n",
      "128/128 [==============================] - 0s 290us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 990/1000\n",
      "128/128 [==============================] - 0s 303us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 991/1000\n",
      "128/128 [==============================] - 0s 281us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 992/1000\n",
      "128/128 [==============================] - 0s 316us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 993/1000\n",
      "128/128 [==============================] - 0s 297us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 994/1000\n",
      "128/128 [==============================] - 0s 305us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 995/1000\n",
      "128/128 [==============================] - 0s 334us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 996/1000\n",
      "128/128 [==============================] - 0s 283us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 997/1000\n",
      "128/128 [==============================] - 0s 298us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 998/1000\n",
      "128/128 [==============================] - 0s 362us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 999/1000\n",
      "128/128 [==============================] - 0s 287us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n",
      "Epoch 1000/1000\n",
      "128/128 [==============================] - 0s 296us/sample - loss: 0.4493 - mse: 0.4493 - val_loss: 0.4997 - val_mse: 0.4997\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Lets first remove previous logs\n",
    "!rm -rf ./logs2/ \n",
    "logdir = \"logs2/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "history = NN_model2.fit(train_Xdf.values, train_Ydf.values,\n",
    "                    batch_size=10,\n",
    "                    epochs=1000, # Number of times we iterate over all the dataset\n",
    "                    #validation_data=(validate_Xdf, validate_Ydf),\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks=[tensorboard_callback]) # to latter see how the training went\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>throw-trash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191935</td>\n",
       "      <td>1.190840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.123253e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.063249e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.235026e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.067060e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correct   throw-trash\n",
       "0  0.191935  1.190840e-03\n",
       "1  1.000000  4.123253e-09\n",
       "2  1.000000  1.063249e-10\n",
       "3  1.000000  6.235026e-12\n",
       "4  1.000000  1.067060e-15"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions2 = pd.DataFrame(NN_model2.predict(test_Xdf),\n",
    "                                columns=['correct', 'throw-trash'])\n",
    "test_predictions2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the output lying in $[0,1]$, it's time to see how good we predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot correction output\n",
    "plt.plot(test_Ydf['correct'].values, label='real')\n",
    "plt.plot(test_predictions2['correct'].values, label='predictions', ls='dashed', lw=3)\n",
    "plt.legend()\n",
    "plt.title('correct')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot trash output\n",
    "plt.plot(test_Ydf['throw-trash'].values, label='real')\n",
    "plt.plot(test_predictions2['throw-trash'].values, label='predictions', ls='dashed', lw=3)\n",
    "plt.legend()\n",
    "plt.title('To the trash')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
